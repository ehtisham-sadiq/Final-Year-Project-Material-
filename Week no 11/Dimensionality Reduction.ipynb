{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbaecf13",
   "metadata": {},
   "source": [
    "# Learning Agenda\n",
    "\n",
    "## Dimensionality Reduction\n",
    "- **Principal Component Analysis (PCA)**\n",
    "- **Linear Discriminant Analysis (LDA)**\n",
    "- **t-SNE**\n",
    "- **Autoencoders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b653099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3eca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e612e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc932ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84cabf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82543934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7fe8847",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "\n",
    "**Dimensionality Reduction** is a process of reducing the number of features in a dataset by retaining only the most important ones. This helps in reducing the complexity of a model, avoiding overfitting, and improving the performance of a machine learning algorithm.\n",
    "\n",
    "\n",
    "<img src=\"images/DR.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ed29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7cd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef77a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4368e29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a517e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72ad9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a0c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e941f25",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "**PCA** is a linear dimensionality reduction technique that transforms the data into a new set of uncorrelated variables called principal components. PCA helps in finding the most important features in the data and reducing the dimensionality of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5ffdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd8a4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961877b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c483c63b",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)\n",
    "\n",
    "**LDA** is a supervised dimensionality reduction technique that aims to reduce the dimensionality of the data while maximizing the separation between classes. LDA is useful in the case of a classification problem where the goal is to find a lower dimensional representation that separates the classes well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2542ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3ac34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf115b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5763954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77c3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dde391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24330ffd",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "\n",
    "**t-SNE** (t-distributed Stochastic Neighbor Embedding) is a non-linear dimensionality reduction technique that maps high-dimensional data to a low-dimensional space while preserving the local structure of the data. t-SNE is useful in visualizing high-dimensional data and finding patterns in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eb0cb4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514eae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d842d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261f430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148b5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12f484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2cc71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "590a6f94",
   "metadata": {},
   "source": [
    "## Autoencoders\n",
    "\n",
    "**Autoencoders** are a type of neural network that aims to reconstruct the input data by encoding it into a lower dimensional representation and then decoding it back to its original form. Autoencoders can be used for dimensionality reduction by training the model to encode and decode the data. The encoding layer can be used as the lower dimensional representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bcab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f8187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f89188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e810f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd6a7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846e700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b390e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "084eadef",
   "metadata": {},
   "source": [
    "## Real World Applications of Dimensionality Reduction\n",
    "\n",
    "#### Principal Component Analysis (PCA):\n",
    "- Image compression and denoising\n",
    "- Stock market analysis and portfolio optimization\n",
    "- Gene expression data analysis in biology\n",
    "\n",
    "#### Linear Discriminant Analysis (LDA):\n",
    "- Face recognition and image classification\n",
    "- Market segmentation and customer profiling\n",
    "- Text classification and sentiment analysis\n",
    "\n",
    "#### t-SNE:\n",
    "- Visualization of high-dimensional data in fields such as biology, genomics, and text mining\n",
    "- Fraud detection and anomaly detection\n",
    "- Marketing research and customer segmentation\n",
    "\n",
    "#### Autoencoders:\n",
    "- Image denoising and image compression\n",
    "- Recommender systems and collaborative filtering\n",
    "- Fraud detection and anomaly detection in finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4c4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fef6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cee32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a0ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf2320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a4a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995da5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fd13460",
   "metadata": {},
   "source": [
    "## Interview Questions\n",
    "\n",
    "\n",
    "- What is dimensionality reduction and why is it important in machine learning?\n",
    "\n",
    "- Can you explain the difference between PCA and LDA?\n",
    "\n",
    "- What is the difference between PCA and t-SNE?\n",
    "\n",
    "- How does PCA work and what are the main steps involved in PCA?\n",
    "\n",
    "- Can you explain the curse of dimensionality and how PCA can help overcome this issue?\n",
    "\n",
    "- What is the difference between PCA and autoencoders?\n",
    "\n",
    "- Can you explain the use case for LDA in machine learning?\n",
    "\n",
    "- How does t-SNE help in visualizing high-dimensional data?\n",
    "\n",
    "- Can you explain how autoencoders work and their applications in dimensionality reduction?\n",
    "\n",
    "- What are some common challenges associated with dimensionality reduction techniques and how can they be overcome?\n",
    "\n",
    "- How do you decide the number of components to retain in PCA?\n",
    "\n",
    "- Can you explain how LDA can be used for feature selection in machine learning?\n",
    "\n",
    "- What is the impact of the perplexity parameter in t-SNE on the visualization results?\n",
    "\n",
    "- How can autoencoders be used for unsupervised learning?\n",
    "\n",
    "- Can you explain how dimensionality reduction techniques can be integrated with other machine learning algorithms?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199d67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
