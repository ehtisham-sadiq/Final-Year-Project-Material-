{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b525179",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Nearest Neighbors Methods - The KNN Algorithm</h1>\n",
    "\n",
    "### KNN Algorithm\n",
    "- Basic Idea\n",
    "- Formal Definition\n",
    "- KNN Decision Boundary\n",
    "- A supervised, non-parametric algorithm\n",
    "- Used for classification and regression\n",
    "- An Instance-based learning algorithm\n",
    "- A lazy learning algorithm\n",
    "- Characteristics of kNN\n",
    "- Practical issues\n",
    "\n",
    "### Similarity/Distance Metrics \n",
    "- Constraints/Properties on Distance Metrics\n",
    "- Euclidean Distance\n",
    "- Manhatten Distance\n",
    "- Minkowski distance\n",
    "- Chebyshev Distance\n",
    "- Norm of a vector and Its Properties\n",
    "- Cosine Distance \n",
    "- Practical Issues in computing distance\n",
    "\n",
    "### The KNN algorithm and Implementation\n",
    "- KNN regression and classification with examples\n",
    "- Space and Time complexity\n",
    "- Choosing the value of K - The Theory.\n",
    "- Tuning the hyperparameter K - The method\n",
    "- KNN: The good, the bad and the ugly\n",
    "    \n",
    "### Algorithm Convergence\n",
    "- Error Convergence\n",
    "- Learning Problem\n",
    "- Bayes Optimal Classifier\n",
    "- 1-NN Error as n → ∞\n",
    "\n",
    "\n",
    "### KNN Enhancements\n",
    "- Parzen Windows and Kernels (Fast KNN) \n",
    "- Performance of KNN Algorithm\n",
    "- K-D Trees\n",
    "- Locality-sensitive Hashing\n",
    "- Inverted Lists\n",
    "\n",
    "### The Curse of Dimensionality\n",
    "- KNN Assumption\n",
    "- Demonstration\n",
    "- How does KNN work at all?\n",
    "\n",
    "### Dimensionality Reduction(Optional)\n",
    "- Why? and Benefits.\n",
    "- Difference between Feature Selection and Feature Extraction\n",
    "- Feature Selection methods\n",
    "- Feature Extraction\n",
    "- Principal Component Analysis\n",
    "    - Geometric Intuition\n",
    "    - Mathematical Formulation\n",
    "    - How do we choose K?\n",
    "    - Practical Consideration and Limitations\n",
    "\n",
    "### Model Evaluation Techniques\n",
    "- Classification Accuracy (0/1 Loss)\n",
    "- TP, TN, FP and FN\n",
    "- Confusion Matrix\n",
    "- Sensitivity, Specificity, Precision Trade-offs, ROC, AUC\n",
    "- F1-Score and Matthew’s Correlation Coefficient\n",
    "- Multi-class Classification, Evaluation, Micro, Macro Averaging\n",
    "\n",
    "**KNN: Python Implementation**    \n",
    "**KNN: Scikit-learn implementation**    \n",
    "**Interview Questions.**   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2bd88",
   "metadata": {},
   "source": [
    "# KNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5065047",
   "metadata": {},
   "source": [
    "### Basic Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d205601",
   "metadata": {},
   "source": [
    "- K-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique.\n",
    "- It assumes the similarity between the new data points and available data points and put the new data points into the category that is most similar to the available categories.Where'k' in KNN is a parameter that refers to the number of nearest neighbours to include in the majority of the voting process.\n",
    "- It stores all the available data and classifies a new data point based on the similarity. This means when new data appears then it can be easily classified into a well suite category by using K- NN algorithm.\n",
    "- **Example:** Suppose, we have an image of a creature that looks similar to cat and dog, but we want to know either it is a cat or dog. So for this identification, we can use the KNN algorithm, as it works on a similarity measure. Our KNN model will find the similar features of the new data set to the cats and dogs images and based on the most similar features it will put it in either cat or dog category.\n",
    "\n",
    "<img src=\"images/knn14.PNG\" height=600px width=600px align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48a032d",
   "metadata": {},
   "source": [
    "### Formal Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7620e7",
   "metadata": {},
   "source": [
    "\"The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning algorithm, which uses proximity to make classifications or predictions about the grouping of an individual data point.\" **(IBM)**\n",
    "\n",
    "**Formal (and borderline incomprehensible) definition of k-NN:**\n",
    "\n",
    "Test point: x\n",
    "\n",
    "Define the set of the k nearest neighbors of x as Sx. Formally Sx is defined as **Sx ⊆ D s.t. |Sx|=k and ∀(x′,y′) ∈ D∖Sx,**\n",
    "\n",
    "**dist(x,x′) ≥ max(x′′,y′′) ∈ Sx dist(x,x′′),**\n",
    " **(x′′,y′′) ∈ Sx**\n",
    "\n",
    "(i.e. every point in D but not in Sx is at least as far away from x as the furthest point in Sx). We can then define the classifier h() as a function returning the most common label in Sx:\n",
    "\n",
    "**h(x) = mode({y′′:(x′′,y′′) ∈ Sx}),**\n",
    "\n",
    "where mode(⋅) means to select the label of the highest occurrence.\n",
    "(Hint: In case of a draw, a good solution is to return the result of k-NN with smaller k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700e175",
   "metadata": {},
   "source": [
    "<img src=\"images/knn1.PNG\" height=600px width=600px align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed2cb0",
   "metadata": {},
   "source": [
    "### How does basic K-NN work?\n",
    "The K-NN working can be explained on the basis of the below algorithm:\n",
    "\n",
    "**Step-1:** Select the number K of the neighbors\n",
    "\n",
    "**Step-2:** Calculate the Euclidean distance of K number of neighbors.\n",
    "\n",
    "**Step-3:** Take the K nearest neighbors as per the calculated Euclidean distance.\n",
    "\n",
    "**Step-4:** Among these k neighbors, count the number of the data points in each category.\n",
    "\n",
    "**Step-5:** Assign the new data points to that category for which the number of the neighbor is maximum.\n",
    "\n",
    "**Step-6:** Our model is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39eb0a",
   "metadata": {},
   "source": [
    "### KNN Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a93795",
   "metadata": {},
   "source": [
    "A decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two or more sets, one for each class. The classifier will classify all the points on one side of the decision boundary as belonging to one class and all those on the other side as belonging to the other class.\n",
    "\n",
    "- We can draw decision boundary for all classification algorithms.\n",
    "- Decision boundary can be linear(if the decision surface is a hyperplane, then the classification problem is linear, and the classes are linearly separable as in SVM) or non linear(in case of Decision Tree). \n",
    "\n",
    "**Value of k**\n",
    "- When K is small, we are restraining the region of a given prediction and forcing our classifier to be “more blind” to the overall distribution. A small value for K provides the most flexible fit, which will have low bias but high variance. Graphically, our decision boundary will be more jagged. \n",
    "- On the other hand, a higher K averages more voters in each prediction and hence is more resilient to outliers. Larger values of K will have smoother decision boundaries which means lower variance but increased bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443e10c",
   "metadata": {},
   "source": [
    "#### k=1\n",
    "<img src=\"images/knn15.PNG\" height=400px width=400px align='center'>\n",
    "\n",
    "#### k=15\n",
    "\n",
    "<img src=\"images/knn16.PNG\" height=350px width=350px align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab53c269",
   "metadata": {},
   "source": [
    "### Supervised and Non-parametric Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca8180",
   "metadata": {},
   "source": [
    "Let’s first start by establishing some definitions and notations. We will use **x** to denote a feature (aka. predictor, attribute) and **y** to denote the target (aka. label, class) we are trying to predict.\n",
    "\n",
    "KNN falls in the supervised learning family of algorithms. Informally, this means that we are given a labelled dataset consiting of training observations **(x,y)** and would like to capture the relationship between x and y. More formally, our goal is to learn a function **h:X→Y** so that given an unseen observation x, **h(x)** can confidently predict the corresponding output y.\n",
    "\n",
    "K-NN is a **non-parametric** algorithm, which means it does not make any assumption on underlying data. It means it makes no explicit assumptions about the functional form of h, avoiding the dangers of mismodeling the underlying distribution of the data. For example, suppose our data is highly non-Gaussian but the learning model we choose assumes a Gaussian form. In that case, our algorithm would make extremely poor predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9dc28",
   "metadata": {},
   "source": [
    "### Classification and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02fbfa0",
   "metadata": {},
   "source": [
    "K-NN algorithm can be used for Regression as well as for Classification but mostly it is used for the Classification problems.KNN algorithm at the training phase just stores the dataset and when it gets new data, then it classifies that data into a category that is much similar to the new data.\n",
    "\n",
    "Regression problems use a similar concept as classification problem, but in this case, the average the k nearest neighbors is taken to make a prediction about a classification. The main distinction here is that classification is used for discrete values, whereas regression is used with continuous ones.\n",
    "\n",
    "**Example:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05298551",
   "metadata": {},
   "source": [
    "- **Classification:** KNN can be used in banking system to predict weather an individual is fit for loan approval? Does that individual have the characteristics similar to the defaulters one?\n",
    "\n",
    "- **Regression:** KNN algorithms can be used to find an individual’s credit rating by comparing with the persons having similar traits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e0e08",
   "metadata": {},
   "source": [
    "# Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9accc0",
   "metadata": {},
   "source": [
    "Distance metrics are a key part of several machine learning algorithms. These distance metrics are used in both supervised and unsupervised learning, generally to calculate the similarity between data points.\n",
    "An effective distance metric improves the performance of our machine learning model, whether that’s for classification tasks or clustering.\n",
    "\n",
    "For the algorithm to work best on a particular dataset we need to choose the most appropriate distance metric accordingly. There are a lot of different distance metrics available, but we are only going to talk about a few widely used ones. Euclidean distance function is the most popular one among all of them as it is set default in the SKlearn KNN classifier library in python.\n",
    "\n",
    "Let’s start with the most commonly used distance metric – Euclidean Distance.\n",
    "\n",
    "### Euclidean Distance\n",
    "\n",
    "Euclidean Distance represents the shortest distance between two points.\n",
    "\n",
    "Most machine learning algorithms including K-Means use this distance metric to measure the similarity between observations. Let’s say we have two points as shown below:\n",
    "\n",
    "<img src=\"images/knn4.PNG\" height=500px width=500px align='center'>\n",
    "\n",
    "So, the Euclidean Distance between these two points A and B will be:\n",
    "\n",
    "<img src=\"images/knn5.PNG\" height=500px width=500px align='center'>\n",
    "\n",
    "Here’s the formula for Euclidean Distance:\n",
    "\n",
    "<img src=\"images/knn7.PNG\" height=300px width=300px align='center'>\n",
    "\n",
    "We use this formula when we are dealing with 2 dimensions. We can generalize this for an n-dimensional space as:\n",
    "\n",
    "<img src=\"images/knn8.PNG\" height=300px width=300px align='center'>\n",
    "\n",
    "Where,\n",
    "- n = number of dimensions\n",
    "- pi, qi = data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a28e10",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a3aaf",
   "metadata": {},
   "source": [
    "Consider two attributes of a chemical, one is acid durability and other is its strenght. On the basis of these two features we classify chemical as good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279873cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8a8ed20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acid Durability</th>\n",
       "      <th>Strenght</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acid Durability  Strenght Output\n",
       "0                7         7    Bad\n",
       "1                7         4    Bad\n",
       "2                3         4   Good\n",
       "3                1         4   Good"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Acid Durability':[7,7,3,1],'Strenght':[7,4,4,4], 'Output':['Bad','Bad','Good','Good']}\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92a5c478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = df['Acid Durability'].values\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcd6a9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = df['Strenght'].values\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e6cce",
   "metadata": {},
   "source": [
    "Lets set k=3 and take new point (3,7) and checks its output using Euclidean Distance formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c4aeca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeED1(x1,x2):\n",
    "    return np.sqrt((x1-3)**2+(x2-7)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "062cca15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.        , 5.        , 3.        , 3.60555128])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = computeED1(x1,x2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28fac431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.        , 3.60555128, 4.        , 5.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aefe248b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 smallest 3 closest point\n",
      "[3.         3.60555128 4.        ]\n"
     ]
    }
   ],
   "source": [
    "k=3\n",
    "print(k, \"smallest 3 closest point\")\n",
    "print(result[:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f793997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acid Durability</th>\n",
       "      <th>Strenght</th>\n",
       "      <th>Output</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Bad</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Bad</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>3.605551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acid Durability  Strenght Output  Euclidean Distance\n",
       "0                7         7    Bad            4.000000\n",
       "1                7         4    Bad            5.000000\n",
       "2                3         4   Good            3.000000\n",
       "3                1         4   Good            3.605551"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Euclidean Distance\"] = computeED1(x1,x2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "193975ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acid Durability</th>\n",
       "      <th>Strenght</th>\n",
       "      <th>Output</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Rank ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Bad</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Bad</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acid Durability  Strenght Output  Euclidean Distance  Rank ED\n",
       "0                7         7    Bad            4.000000        3\n",
       "1                7         4    Bad            5.000000        4\n",
       "2                3         4   Good            3.000000        1\n",
       "3                1         4   Good            3.605551        2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Rank ED\"] = [3,4,1,2]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106ffdb",
   "metadata": {},
   "source": [
    "So, two smallest distance belong to \"Good\" that is why new point (3,7) is a Good chemical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c1cad",
   "metadata": {},
   "source": [
    "### Manhatten Distance\n",
    "\n",
    "Manhattan Distance is the sum of absolute differences between points across all the dimensions.\n",
    "\n",
    "                                        OR\n",
    "The distance between two points is the sum of the absolute differences of their Cartesian coordinates.\n",
    "\n",
    "\n",
    "This distance is also known as taxicab distance or city block distance, that is because the way this distance is calculated. This distance is preferred over Euclidean distance when we have a case of high dimensionality.\n",
    "\n",
    "Again consider the above points. We can represent Manhattan Distance as:\n",
    "\n",
    "<img src=\"images/knn6.PNG\" height=500px width=500px align='center'>\n",
    "\n",
    "Since the above representation is 2 dimensional, to calculate Manhattan Distance, we will take the sum of absolute distances in both the x and y directions. So, the Manhattan distance in a 2-dimensional space is given as:\n",
    "\n",
    "<img src=\"images/knn9.PNG\" height=300px width=300px align='center'>\n",
    "\n",
    "And the generalized formula for an n-dimensional space is given as:\n",
    "\n",
    "<img src=\"images/knn10.PNG\" height=300px width=300px align='center'>\n",
    "\n",
    "Where,\n",
    "- n = number of dimensions\n",
    "- pi, qi = data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ac90345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMD(x1,x2):\n",
    "    return (x1-3)**2+(x2-7)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "026ecd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acid Durability</th>\n",
       "      <th>Strenght</th>\n",
       "      <th>Output</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Rank ED</th>\n",
       "      <th>Manhatten Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Bad</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Bad</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acid Durability  Strenght Output  Euclidean Distance  Rank ED  \\\n",
       "0                7         7    Bad            4.000000        3   \n",
       "1                7         4    Bad            5.000000        4   \n",
       "2                3         4   Good            3.000000        1   \n",
       "3                1         4   Good            3.605551        2   \n",
       "\n",
       "   Manhatten Distance  \n",
       "0                  16  \n",
       "1                  25  \n",
       "2                   9  \n",
       "3                  13  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Manhatten Distance\"] = computeMD(x1,x2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25c934a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acid Durability</th>\n",
       "      <th>Strenght</th>\n",
       "      <th>Output</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Rank ED</th>\n",
       "      <th>Manhatten Distance</th>\n",
       "      <th>Rank MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Bad</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Bad</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acid Durability  Strenght Output  Euclidean Distance  Rank ED  \\\n",
       "0                7         7    Bad            4.000000        3   \n",
       "1                7         4    Bad            5.000000        4   \n",
       "2                3         4   Good            3.000000        1   \n",
       "3                1         4   Good            3.605551        2   \n",
       "\n",
       "   Manhatten Distance  Rank MD  \n",
       "0                  16        3  \n",
       "1                  25        4  \n",
       "2                   9        1  \n",
       "3                  13        2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Rank MD\"] = [3,4,1,2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211d4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35388819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbedc4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eb1967a",
   "metadata": {},
   "source": [
    "### Minkowski Distance\n",
    "Minkowski Distance is the generalized form of Euclidean and Manhattan Distance.\n",
    "\n",
    "It is a metric intended for real-valued vector spaces. We can calculate Minkowski distance only in a normed vector space, which means in a space where distances can be represented as a vector that has a length and the lengths cannot be negative.\n",
    "\n",
    "The formula for Minkowski Distance is given as:\n",
    "\n",
    "<img src=\"images/knn11.PNG\" height=300px width=300px align='center'>\n",
    "\n",
    "This above formula for Minkowski distance is in generalized form and we can manipulate it to get different distance metrices.\n",
    "\n",
    "The p value in the formula can be manipulated to give us different distances like:\n",
    "\n",
    "- p = 1, when p is set to 1 we get Manhattan distance\n",
    "- p = 2, when p is set to 2 we get Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dcf02f",
   "metadata": {},
   "source": [
    "## Algorithm Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e62154",
   "metadata": {},
   "source": [
    "### Error Convergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77313d0c",
   "metadata": {},
   "source": [
    "When number of data points in th training data increases, then error rate reaches to some threshold value. \n",
    "The error of 1-NN Classifier converges when number of points in data increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282a962",
   "metadata": {},
   "source": [
    "### Learning Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553d000",
   "metadata": {},
   "source": [
    "For this purpose we denote entire data set as:\n",
    "\n",
    "**D = {(x1,y1),(x2,y2),...(xn,yn) ⊆ X^d x Y}** \n",
    "\n",
    "We want to predict the label for input for which the label is unkown\n",
    "\n",
    "We assume data points (xi,yi) are drawn from an unkown distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f00ec",
   "metadata": {},
   "source": [
    "### Bayes Optimal Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e406eebe",
   "metadata": {},
   "source": [
    "Best prediction: \n",
    "\n",
    "**y∗ = hopt = argmaxyP(y|x)**\n",
    "\n",
    "Error of the BayesOpt classifier\n",
    "\n",
    "**ϵBayesOpt = 1−P(hopt(x)|y) = 1−P(y∗|x)**\n",
    "\n",
    "You can never do better than the Bayes Optimal Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e8448",
   "metadata": {},
   "source": [
    "### 1-NN Error as n → ∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42d1d6",
   "metadata": {},
   "source": [
    "As n→∞, the 1-NN error is no more than twice the error of the Bayes Optimal classifier.\n",
    "\n",
    "Let xNN be the nearest neighbor of our test point xt. As **n→∞**, **dist(xNN,x)→0**, i.e. **xNN→xt**. (This means the nearest neighbor is identical to xt.) You return the label of xNN. What is the probability that this is not the label of x? (This is the probability of drawing two different label of x)\n",
    "\n",
    "**ϵNN = P(y∗|xt)(1−P(y∗|xNN)) + P(y∗|xNN)(1−P(y∗|xt)) ≤ (1−P(y∗|xNN) + (1−P(y∗|xt) = 2(1−P(y∗|xt) = 2ϵBayesOpt,**\n",
    "\n",
    "where the inequality follows from P(y∗|x+)≤1 and P(y∗|xNN)≤1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ebcef",
   "metadata": {},
   "source": [
    "## KNN Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ab54f",
   "metadata": {},
   "source": [
    "### Parzen Windows and Kernels (Fast KNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a775a",
   "metadata": {},
   "source": [
    "Instead of fix the number of neighbours, Parzen Windows fix the size of area or a region with fixed size of radius \n",
    "\n",
    "<img src=\"images/knn17.PNG\" height=600px width=600px align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedda72",
   "metadata": {},
   "source": [
    "### Performance of KNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f27e0e",
   "metadata": {},
   "source": [
    "- No assumption about training data\n",
    "- Non parametric approach\n",
    "- Need to handle missing values\n",
    "- Sensitive to outliers\n",
    "- Computationally Expensive O(nd) n= no.of samples, d= dimensions\n",
    "- Slow at testing time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17c60e",
   "metadata": {},
   "source": [
    "### K-D Trees\n",
    "We can make knn fast by reducing **n** and **d**. K-D Trees allows you to find m potential neighbours i.e **m << n**, if we have low dimensional and real value data.\n",
    "\n",
    "**O(d log2 n)**,\n",
    "inexact technique as you miss neighbours\n",
    "only works when **d << n**\n",
    "\n",
    "#### Steps:\n",
    "- Pick random dimension\n",
    "- Find median\n",
    "- Split data\n",
    "- Repeat\n",
    "\n",
    "<img src=\"images/knn19.PNG\" height=600px width=600px align='center'>\n",
    "\n",
    "<img src=\"images/knn18.PNG\" height=600px width=600px align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074597b1",
   "metadata": {},
   "source": [
    "### Inverted List\n",
    "If your data is high dimensional and sparse\n",
    "\n",
    "**O(n'd')**\n",
    "\n",
    "exact technique as you dont miss neighbours.\n",
    "\n",
    "It is a data structures used by search engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ff3b29",
   "metadata": {},
   "source": [
    "### Locally Sensitive Hashing\n",
    "If your data is high dimensional and real value\n",
    "\n",
    "**O(n'd')**\n",
    "\n",
    "inexact technique as you miss neighbours only works when **n' << n**\n",
    "\n",
    "#### Steps:\n",
    "- Draw k random hyperplanes\n",
    "- Space sliced into 2^k regions, each region has linear slides and are mutually exclusive\n",
    "- When apoint x comes, compare it only to training points in that region\n",
    "\n",
    "<img src=\"images/knn20.PNG\" height=500px width=500px align='center'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5df2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9117b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.46860857e+00, -1.83256468e+00,  2.92913502e+00,\n",
       "         -1.58752889e+00],\n",
       "        [ 1.49560407e+00, -5.03016146e-01,  3.34799662e-01,\n",
       "          1.41306917e+00],\n",
       "        [-5.87512817e-01, -6.99464894e-03,  3.53586145e-01,\n",
       "         -1.35523642e+00],\n",
       "        [ 1.62804920e+00, -1.56355157e+00,  2.77343570e+00,\n",
       "         -2.43525035e+00],\n",
       "        [-1.07637151e+00,  8.97026797e-01, -1.50950251e+00,\n",
       "          1.07541303e+00],\n",
       "        [-1.07301040e+00,  3.55946035e-01, -2.28488201e-01,\n",
       "         -1.03311348e+00],\n",
       "        [ 1.86421051e+00, -5.72796908e-01,  2.88819837e-01,\n",
       "          1.97327676e+00],\n",
       "        [-7.97059544e-01,  6.51590924e-01, -1.08777124e+00,\n",
       "          7.46826653e-01],\n",
       "        [-3.43040211e-01,  1.28589509e-01, -1.08124996e-01,\n",
       "         -2.72427209e-01],\n",
       "        [ 2.91591039e+00, -2.20158151e+00,  3.54752570e+00,\n",
       "         -2.01974420e+00],\n",
       "        [-1.41274837e+00,  7.75902302e-01, -1.02935939e+00,\n",
       "         -1.58565165e-01],\n",
       "        [ 9.84334951e-01, -3.66231453e-01,  3.03740521e-01,\n",
       "          7.92466134e-01],\n",
       "        [-5.39987803e-01,  2.09677379e-01, -1.87419828e-01,\n",
       "         -4.00434825e-01],\n",
       "        [ 6.33170535e-01, -1.45703382e-01, -1.77174650e-02,\n",
       "          8.61241111e-01],\n",
       "        [-7.58610989e-01,  6.74469964e-01, -1.16407348e+00,\n",
       "          9.23205141e-01],\n",
       "        [-9.70679834e-01,  8.27015199e-01, -1.40412532e+00,\n",
       "          1.04048486e+00],\n",
       "        [ 1.85880410e+00, -6.46036821e-01,  4.65578211e-01,\n",
       "          1.67462193e+00],\n",
       "        [ 9.44913659e-01, -3.78412043e-01,  3.55233915e-01,\n",
       "          6.55729869e-01],\n",
       "        [-1.11019707e+00,  9.27711335e-01, -1.56285523e+00,\n",
       "          1.11896616e+00],\n",
       "        [ 1.18962969e+00, -3.76451451e-01,  2.10214441e-01,\n",
       "          1.21649827e+00],\n",
       "        [-2.32646209e+00,  1.26305919e+00, -1.66033182e+00,\n",
       "         -3.18485433e-01],\n",
       "        [-1.28434124e+00,  5.84345793e-01, -6.48820021e-01,\n",
       "         -6.17504824e-01],\n",
       "        [-4.08827830e-01,  4.69461815e-01, -8.78622069e-01,\n",
       "          9.12005447e-01],\n",
       "        [-6.13375201e-01,  4.76678992e-01, -7.78404772e-01,\n",
       "          4.77918689e-01],\n",
       "        [ 7.13394322e-01, -6.82187036e-01,  1.20830781e+00,\n",
       "         -1.05558350e+00],\n",
       "        [ 3.03795980e-01, -2.46387371e-01,  4.09943142e-01,\n",
       "         -2.76969498e-01],\n",
       "        [ 1.29295243e+00, -4.88035529e-01,  4.15521870e-01,\n",
       "          1.01362927e+00],\n",
       "        [ 9.17111796e-01, -2.64783370e-01,  1.01759316e-01,\n",
       "          1.03728540e+00],\n",
       "        [ 4.17577519e-01, -1.86687747e-01,  2.03125088e-01,\n",
       "          2.13676936e-01],\n",
       "        [-2.41008280e+00,  1.07611435e+00, -1.16910646e+00,\n",
       "         -1.23860894e+00],\n",
       "        [ 1.09801141e+00, -7.90940585e-01,  1.24555151e+00,\n",
       "         -6.11608500e-01],\n",
       "        [-4.93099500e-01,  4.92243135e-02,  1.66130736e-01,\n",
       "         -9.21978117e-01],\n",
       "        [ 1.15074863e+00, -9.68009501e-01,  1.63514450e+00,\n",
       "         -1.18491547e+00],\n",
       "        [-6.25704839e-01,  5.45891340e-01, -9.35439973e-01,\n",
       "          7.20735477e-01],\n",
       "        [-2.04141012e+00,  7.82502969e-01, -6.84405429e-01,\n",
       "         -1.55363514e+00],\n",
       "        [-7.27298840e-01,  6.26815025e-01, -1.06904097e+00,\n",
       "          8.07601407e-01],\n",
       "        [-1.62618453e+00,  1.31834362e+00, -2.19309919e+00,\n",
       "          1.48047630e+00],\n",
       "        [-1.07305627e+00,  9.35226309e-01, -1.60197800e+00,\n",
       "          1.23230127e+00],\n",
       "        [-1.08055188e+00,  8.65688559e-01, -1.43279935e+00,\n",
       "          9.43403351e-01],\n",
       "        [-9.28879199e-01,  7.87394136e-01, -1.33415800e+00,\n",
       "          9.80006766e-01],\n",
       "        [ 1.67735108e+00, -1.24370242e+00,  1.98676995e+00,\n",
       "         -1.07291531e+00],\n",
       "        [ 7.87147357e-02, -8.53425604e-03, -2.49159554e-02,\n",
       "          1.44532175e-01],\n",
       "        [-8.58830512e-01,  3.97962992e-01, -4.50968527e-01,\n",
       "         -3.84704832e-01],\n",
       "        [-1.55921050e+00,  3.77701668e-01, -1.18475055e-03,\n",
       "         -2.04692554e+00],\n",
       "        [ 3.55975664e-01, -2.35697974e-01,  3.54667179e-01,\n",
       "         -1.17228991e-01],\n",
       "        [ 1.80645939e+00, -6.42955551e-01,  4.88297570e-01,\n",
       "          1.56836441e+00],\n",
       "        [ 7.23043992e-01, -2.01548728e-01,  6.31439334e-02,\n",
       "          8.45964076e-01],\n",
       "        [-1.19425691e+00,  1.06947564e+00, -1.85077153e+00,\n",
       "          1.48340509e+00],\n",
       "        [-1.26989059e+00,  1.05615360e+00, -1.77579999e+00,\n",
       "          1.26035842e+00],\n",
       "        [ 1.62316960e+00, -1.44169219e+00,  2.48729711e+00,\n",
       "         -1.96969689e+00]]),\n",
       " array([1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.make_classification(n_samples=50,n_features=4, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6053e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d89f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance: 2.8284271247461903\n",
      "Manhattan distance: 4\n",
      "Cosine similarity: 0.9838699100999074\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "def manhattan_distance(x1, y1, x2, y2):\n",
    "    return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "def cosine_similarity(x1, y1, x2, y2):\n",
    "    dot_product = x1 * x2 + y1 * y2\n",
    "    norm1 = math.sqrt(x1 ** 2 + y1 ** 2)\n",
    "    norm2 = math.sqrt(x2 ** 2 + y2 ** 2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# calculate Euclidean distance\n",
    "distance = euclidean_distance(1, 2, 3, 4)\n",
    "print(\"Euclidean distance:\", distance)\n",
    "\n",
    "# calculate Manhattan distance\n",
    "distance = manhattan_distance(1, 2, 3, 4)\n",
    "print(\"Manhattan distance:\", distance)\n",
    "\n",
    "# calculate cosine similarity\n",
    "similarity = cosine_similarity(1, 2, 3, 4)\n",
    "print(\"Cosine similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955b733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
