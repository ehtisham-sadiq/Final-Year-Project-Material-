{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b525179",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Nearest Neighbors Methods - The KNN Algorithm</h1>\n",
    "\n",
    "### KNN Algorithm\n",
    "- Basic Idea\n",
    "- Formal Definition\n",
    "- KNN Decision Boundary\n",
    "- A supervised, non-parametric algorithm\n",
    "- Used for classification and regression\n",
    "- An Instance-based learning algorithm\n",
    "- A lazy learning algorithm\n",
    "- Characteristics of kNN\n",
    "- Practical issues\n",
    "\n",
    "### Similarity/Distance Metrics \n",
    "- Constraints/Properties on Distance Metrics\n",
    "- Euclidean Distance\n",
    "- Manhatten Distance\n",
    "- Minkowski distance\n",
    "- Chebyshev Distance\n",
    "- Norm of a vector and Its Properties\n",
    "- Cosine Distance \n",
    "- Practical Issues in computing distance\n",
    "\n",
    "### The KNN algorithm and Implementation\n",
    "- KNN regression and classification with examples\n",
    "- Space and Time complexity\n",
    "- Choosing the value of K - The Theory.\n",
    "- Tuning the hyperparameter K - The method\n",
    "- KNN: The good, the bad and the ugly\n",
    "    \n",
    "### Algorithm Convergence\n",
    "- Error Convergence\n",
    "- Learning Problem\n",
    "- Bayes Optimal Classifier\n",
    "- 1-NN Error as n → ∞\n",
    "\n",
    "\n",
    "### KNN Enhancements\n",
    "- Parzen Windows and Kernels (Fast KNN) \n",
    "- Performance of KNN Algorithm\n",
    "- K-D Trees\n",
    "- Locality-sensitive Hashing\n",
    "- Inverted Lists\n",
    "\n",
    "### The Curse of Dimensionality\n",
    "- KNN Assumption\n",
    "- Demonstration\n",
    "- How does KNN work at all?\n",
    "\n",
    "### Dimensionality Reduction(Optional)\n",
    "- Why? and Benefits.\n",
    "- Difference between Feature Selection and Feature Extraction\n",
    "- Feature Selection methods\n",
    "- Feature Extraction\n",
    "- Principal Component Analysis\n",
    "    - Geometric Intuition\n",
    "    - Mathematical Formulation\n",
    "    - How do we choose K?\n",
    "    - Practical Consideration and Limitations\n",
    "\n",
    "### Model Evaluation Techniques\n",
    "- Classification Accuracy (0/1 Loss)\n",
    "- TP, TN, FP and FN\n",
    "- Confusion Matrix\n",
    "- Sensitivity, Specificity, Precision Trade-offs, ROC, AUC\n",
    "- F1-Score and Matthew’s Correlation Coefficient\n",
    "- Multi-class Classification, Evaluation, Micro, Macro Averaging\n",
    "\n",
    "**KNN: Python Implementation**    \n",
    "**KNN: Scikit-learn implementation**    \n",
    "**Interview Questions.**   "
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "markdown",
   "id": "13c2bd88",
   "metadata": {},
   "source": [
    "# KNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5065047",
   "metadata": {},
   "source": [
    "### Basic Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d205601",
   "metadata": {},
   "source": [
    "- K-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique.\n",
    "- It assumes the similarity between the new data points and available data points and put the new data points into the category that is most similar to the available categories.Where'k' in KNN is a parameter that refers to the number of nearest neighbours to include in the majority of the voting process.\n",
    "- It stores all the available data and classifies a new data point based on the similarity. This means when new data appears then it can be easily classified into a well suite category by using K- NN algorithm.\n",
    "- **Example:** Suppose, we have an image of a creature that looks similar to cat and dog, but we want to know either it is a cat or dog. So for this identification, we can use the KNN algorithm, as it works on a similarity measure. Our KNN model will find the similar features of the new data set to the cats and dogs images and based on the most similar features it will put it in either cat or dog category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48a032d",
   "metadata": {},
   "source": [
    "### Formal Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7620e7",
   "metadata": {},
   "source": [
    "\"The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning algorithm, which uses proximity to make classifications or predictions about the grouping of an individual data point.\" (IBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700e175",
   "metadata": {},
   "source": [
    "<img src=\"images/knn1.PNG\" height=600px width=600px align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed2cb0",
   "metadata": {},
   "source": [
    "### How does basic K-NN work?\n",
    "The K-NN working can be explained on the basis of the below algorithm:\n",
    "\n",
    "**Step-1:** Select the number K of the neighbors\n",
    "\n",
    "**Step-2:** Calculate the Euclidean distance of K number of neighbors.\n",
    "\n",
    "**Step-3:** Take the K nearest neighbors as per the calculated Euclidean distance.\n",
    "\n",
    "**Step-4:** Among these k neighbors, count the number of the data points in each category.\n",
    "\n",
    "**Step-5:** Assign the new data points to that category for which the number of the neighbor is maximum.\n",
    "\n",
    "**Step-6:** Our model is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39eb0a",
   "metadata": {},
   "source": [
    "### KNN Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a93795",
   "metadata": {},
   "source": [
    "A decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two or more sets, one for each class. The classifier will classify all the points on one side of the decision boundary as belonging to one class and all those on the other side as belonging to the other class.\n",
    "\n",
    "- We can draw decision boundary for all classification algorithms.\n",
    "- Decision boundary can be linear(if the decision surface is a hyperplane, then the classification problem is linear, and the classes are linearly separable as in SVM) or non linear(in case of Decision Tree). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443e10c",
   "metadata": {},
   "source": [
    "<img src=\"images/knn2.PNG\" height=600px width=600px align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab53c269",
   "metadata": {},
   "source": [
    "### Supervised and Non-parametric Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca8180",
   "metadata": {},
   "source": [
    "Let’s first start by establishing some definitions and notations. We will use **x** to denote a feature (aka. predictor, attribute) and **y** to denote the target (aka. label, class) we are trying to predict.\n",
    "\n",
    "KNN falls in the supervised learning family of algorithms. Informally, this means that we are given a labelled dataset consiting of training observations **(x,y)** and would like to capture the relationship between x and y. More formally, our goal is to learn a function **h:X→Y** so that given an unseen observation x, **h(x)** can confidently predict the corresponding output y.\n",
    "\n",
    "K-NN is a **non-parametric** algorithm, which means it does not make any assumption on underlying data. It means it makes no explicit assumptions about the functional form of h, avoiding the dangers of mismodeling the underlying distribution of the data. For example, suppose our data is highly non-Gaussian but the learning model we choose assumes a Gaussian form. In that case, our algorithm would make extremely poor predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9dc28",
   "metadata": {},
   "source": [
    "### Classification and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02fbfa0",
   "metadata": {},
   "source": [
    "K-NN algorithm can be used for Regression as well as for Classification but mostly it is used for the Classification problems.KNN algorithm at the training phase just stores the dataset and when it gets new data, then it classifies that data into a category that is much similar to the new data.\n",
    "\n",
    "Regression problems use a similar concept as classification problem, but in this case, the average the k nearest neighbors is taken to make a prediction about a classification. The main distinction here is that classification is used for discrete values, whereas regression is used with continuous ones.\n",
    "\n",
    "**Example:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e416ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
>>>>>>> 45259749a3a4a8e78a78b54bd6bf3d63fa75eacb
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5df2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9117b32",
<<<<<<< HEAD
   "metadata": {
    "scrolled": true
   },
=======
   "metadata": {},
>>>>>>> 45259749a3a4a8e78a78b54bd6bf3d63fa75eacb
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.46860857e+00, -1.83256468e+00,  2.92913502e+00,\n",
       "         -1.58752889e+00],\n",
       "        [ 1.49560407e+00, -5.03016146e-01,  3.34799662e-01,\n",
       "          1.41306917e+00],\n",
       "        [-5.87512817e-01, -6.99464894e-03,  3.53586145e-01,\n",
       "         -1.35523642e+00],\n",
       "        [ 1.62804920e+00, -1.56355157e+00,  2.77343570e+00,\n",
       "         -2.43525035e+00],\n",
       "        [-1.07637151e+00,  8.97026797e-01, -1.50950251e+00,\n",
       "          1.07541303e+00],\n",
       "        [-1.07301040e+00,  3.55946035e-01, -2.28488201e-01,\n",
       "         -1.03311348e+00],\n",
       "        [ 1.86421051e+00, -5.72796908e-01,  2.88819837e-01,\n",
       "          1.97327676e+00],\n",
       "        [-7.97059544e-01,  6.51590924e-01, -1.08777124e+00,\n",
       "          7.46826653e-01],\n",
       "        [-3.43040211e-01,  1.28589509e-01, -1.08124996e-01,\n",
       "         -2.72427209e-01],\n",
       "        [ 2.91591039e+00, -2.20158151e+00,  3.54752570e+00,\n",
       "         -2.01974420e+00],\n",
       "        [-1.41274837e+00,  7.75902302e-01, -1.02935939e+00,\n",
       "         -1.58565165e-01],\n",
       "        [ 9.84334951e-01, -3.66231453e-01,  3.03740521e-01,\n",
       "          7.92466134e-01],\n",
       "        [-5.39987803e-01,  2.09677379e-01, -1.87419828e-01,\n",
       "         -4.00434825e-01],\n",
       "        [ 6.33170535e-01, -1.45703382e-01, -1.77174650e-02,\n",
       "          8.61241111e-01],\n",
       "        [-7.58610989e-01,  6.74469964e-01, -1.16407348e+00,\n",
       "          9.23205141e-01],\n",
       "        [-9.70679834e-01,  8.27015199e-01, -1.40412532e+00,\n",
       "          1.04048486e+00],\n",
       "        [ 1.85880410e+00, -6.46036821e-01,  4.65578211e-01,\n",
       "          1.67462193e+00],\n",
       "        [ 9.44913659e-01, -3.78412043e-01,  3.55233915e-01,\n",
       "          6.55729869e-01],\n",
       "        [-1.11019707e+00,  9.27711335e-01, -1.56285523e+00,\n",
       "          1.11896616e+00],\n",
       "        [ 1.18962969e+00, -3.76451451e-01,  2.10214441e-01,\n",
       "          1.21649827e+00],\n",
       "        [-2.32646209e+00,  1.26305919e+00, -1.66033182e+00,\n",
       "         -3.18485433e-01],\n",
       "        [-1.28434124e+00,  5.84345793e-01, -6.48820021e-01,\n",
       "         -6.17504824e-01],\n",
       "        [-4.08827830e-01,  4.69461815e-01, -8.78622069e-01,\n",
       "          9.12005447e-01],\n",
       "        [-6.13375201e-01,  4.76678992e-01, -7.78404772e-01,\n",
       "          4.77918689e-01],\n",
       "        [ 7.13394322e-01, -6.82187036e-01,  1.20830781e+00,\n",
       "         -1.05558350e+00],\n",
       "        [ 3.03795980e-01, -2.46387371e-01,  4.09943142e-01,\n",
       "         -2.76969498e-01],\n",
       "        [ 1.29295243e+00, -4.88035529e-01,  4.15521870e-01,\n",
       "          1.01362927e+00],\n",
       "        [ 9.17111796e-01, -2.64783370e-01,  1.01759316e-01,\n",
       "          1.03728540e+00],\n",
       "        [ 4.17577519e-01, -1.86687747e-01,  2.03125088e-01,\n",
       "          2.13676936e-01],\n",
       "        [-2.41008280e+00,  1.07611435e+00, -1.16910646e+00,\n",
       "         -1.23860894e+00],\n",
       "        [ 1.09801141e+00, -7.90940585e-01,  1.24555151e+00,\n",
       "         -6.11608500e-01],\n",
       "        [-4.93099500e-01,  4.92243135e-02,  1.66130736e-01,\n",
       "         -9.21978117e-01],\n",
       "        [ 1.15074863e+00, -9.68009501e-01,  1.63514450e+00,\n",
       "         -1.18491547e+00],\n",
       "        [-6.25704839e-01,  5.45891340e-01, -9.35439973e-01,\n",
       "          7.20735477e-01],\n",
       "        [-2.04141012e+00,  7.82502969e-01, -6.84405429e-01,\n",
       "         -1.55363514e+00],\n",
       "        [-7.27298840e-01,  6.26815025e-01, -1.06904097e+00,\n",
       "          8.07601407e-01],\n",
       "        [-1.62618453e+00,  1.31834362e+00, -2.19309919e+00,\n",
       "          1.48047630e+00],\n",
       "        [-1.07305627e+00,  9.35226309e-01, -1.60197800e+00,\n",
       "          1.23230127e+00],\n",
       "        [-1.08055188e+00,  8.65688559e-01, -1.43279935e+00,\n",
       "          9.43403351e-01],\n",
       "        [-9.28879199e-01,  7.87394136e-01, -1.33415800e+00,\n",
       "          9.80006766e-01],\n",
       "        [ 1.67735108e+00, -1.24370242e+00,  1.98676995e+00,\n",
       "         -1.07291531e+00],\n",
       "        [ 7.87147357e-02, -8.53425604e-03, -2.49159554e-02,\n",
       "          1.44532175e-01],\n",
       "        [-8.58830512e-01,  3.97962992e-01, -4.50968527e-01,\n",
       "         -3.84704832e-01],\n",
       "        [-1.55921050e+00,  3.77701668e-01, -1.18475055e-03,\n",
       "         -2.04692554e+00],\n",
       "        [ 3.55975664e-01, -2.35697974e-01,  3.54667179e-01,\n",
       "         -1.17228991e-01],\n",
       "        [ 1.80645939e+00, -6.42955551e-01,  4.88297570e-01,\n",
       "          1.56836441e+00],\n",
       "        [ 7.23043992e-01, -2.01548728e-01,  6.31439334e-02,\n",
       "          8.45964076e-01],\n",
       "        [-1.19425691e+00,  1.06947564e+00, -1.85077153e+00,\n",
       "          1.48340509e+00],\n",
       "        [-1.26989059e+00,  1.05615360e+00, -1.77579999e+00,\n",
       "          1.26035842e+00],\n",
       "        [ 1.62316960e+00, -1.44169219e+00,  2.48729711e+00,\n",
       "         -1.96969689e+00]]),\n",
       " array([1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.make_classification(n_samples=50,n_features=4, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6053e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "211b1659",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3dcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1f713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7899473c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f0d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3c117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b9f74",
=======
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d89f25",
>>>>>>> 45259749a3a4a8e78a78b54bd6bf3d63fa75eacb
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.10"
=======
   "version": "3.9.12"
>>>>>>> 45259749a3a4a8e78a78b54bd6bf3d63fa75eacb
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
