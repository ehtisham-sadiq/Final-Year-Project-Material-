{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9591db7b",
   "metadata": {},
   "source": [
    "<img src=\"images/MLvsDL.jpeg\" height=400px width=400px>\n",
    "\n",
    "<h4 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">Deep learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher-level features from the raw input. (Wikipedia- Andrew Ng )</div></h4>\n",
    "\n",
    "<img src='images/combine_images (1).jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14217586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87356327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3271bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfbc4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb7ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7645ea17",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction to Deep Learning and Neural Networks\n",
    "\n",
    "### Introduction\n",
    "- Definition of deep learning and neural networks\n",
    "- Applications of deep learning and neural networks\n",
    "- Deep learning frameworks\n",
    "\n",
    "### Building Blocks of a Neural Network\n",
    "- Neurons and their functionalities\n",
    "- Activation functions and their importance\n",
    "- Layers: input, hidden, and output\n",
    "- Forward propagation\n",
    "\n",
    "### Types of Neural Networks\n",
    "- Convolution   Neural Network\n",
    "- Recurrent Neural Network\n",
    "\n",
    "### Introduction to TensorFlow and Keras Libraries\n",
    "\n",
    "- Overview of TensorFlow and Keras libraries\n",
    "- Advantages and disadvantages of using these libraries\n",
    "\n",
    "\n",
    "### Building and Training a Simple Neural Network using Keras\n",
    "\n",
    "- Installing and importing the required libraries\n",
    "- Loading and preparing the data\n",
    "- Building the neural network model\n",
    "- Compiling the model with a loss function and optimizer\n",
    "- Training and evaluating the model\n",
    "\n",
    "### Practice Building a Neural Network for a Basic Classification Problem\n",
    "- Problem statement and dataset description\n",
    "- Loading and preparing the data\n",
    "- Building the neural network model\n",
    "- Compiling the model with a loss function and optimizer\n",
    "- Training and evaluating the model\n",
    "- Analyzing the model's performance\n",
    "\n",
    "### Conclusion\n",
    "- Summary of key concepts and techniques covered\n",
    "- Future directions and additional resources for deep learning and neural networks\n",
    "\n",
    "### Project:\n",
    "- Natural language processing using NNs: Build a model to perform natural language processing tasks such as machine translation or text classification.\n",
    "\n",
    "### Interview Questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c21d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517372b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22991b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72d119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33422c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc681ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc88b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39c7cc56",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ea89e",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">a. What is Deep Learning? </h2>\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">Deep learning is a machine learning method that involves teaching artificial neural networks to learn from the input data by automatically discovering the relevant features required for solving complex problems. (Geoffrey Hinton – Professor at the University of Toronto)</div></hp>\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"> Deep learning is a set of techniques that allow machines to learn by example, by constructing layered representations of data that enable learning and decision-making. (Yoshua Bengio- Professor at the University of Montreal) </div> </p>\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"> Deep learning is a subfield of machine learning that is concerned with algorithms inspired by the structure and function of the brain, which is also known as artificial neural networks. (Yann LeCun - Director of AI Research at Facebook) </div></p>\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"> Deep learning refers to artificial neural networks that are composed of many layers. (Ian Goodfellow - American computer scientist) </div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5c071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44763ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7479c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d1b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1537c0e5",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">b. Big Picture </h2>\n",
    "<img src=\"images/DS_MLRelationship.webp\" height=400px width=400px align=right>\n",
    "\n",
    "- **Artificial Intelligence (AI)**: Artificial Intelligence is the overarching field of study that focuses on developing intelligent systems that can perform tasks that usually require human-like intelligence.\n",
    "<br>\n",
    "- **Machine Learning (ML):** Machine Learning is a subset of AI that involves the use of statistical techniques and algorithms to enable machines to learn from data without being explicitly programmed.\n",
    "<br>\n",
    "\n",
    "- **Deep Learning (DL):** Deep Learning is a subset of machine learning that uses artificial neural networks with multiple layers to learn and extract features from complex data, such as images, video, and speech.\n",
    "<br>\n",
    "\n",
    "- **Data Science (DS):** Data Science is the field of study that involves the use of statistical and computational techniques to extract insights and knowledge from data.\n",
    "<br>\n",
    "\n",
    "- **Mathematics and Statistics:** Mathematics and Statistics are the foundational disciplines that provide the theoretical framework for developing and evaluating machine learning and deep learning algorithms.\n",
    "<br>\n",
    "\n",
    "- **Visualization:** Visualization is the process of representing data in a visual form to facilitate understanding and communication of insights and patterns in the data.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afca69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f08789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e0ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7ce06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707edbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "578a24a7",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">c. Why DL is getting Famous now?</h2> \n",
    "<br>\n",
    "<img src=\"images/famous.jpeg\" height=500px width=500px align=right>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Availability of large amounts of data**\n",
    "\n",
    "\n",
    "- **Advancements in computing power**\n",
    "\n",
    "\n",
    "- **Improved algorithms and architectures**\n",
    "\n",
    "\n",
    "- **Success stories in various fields**\n",
    "\n",
    "\n",
    "- **Availability of open-source tools and libraries**\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "> <i>All the advancements, algorithms, architecture, success stories, tools and libraries, I will explain later in the notebook.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87296fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ef036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbaff9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98075985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0fa60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56849540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6397f9c3",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">d. History of Deep Learning</h2> \n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"> \"AI began with an ancient wish to forge the gods.\" (Pamela McCorduck, Machines Who Think, 1979) </div></p>\n",
    "\n",
    "<img src=\"images/gub.png\" height=150px width=150px align=right>\n",
    "\n",
    "- The concept of **AI** dates back to the earliest human civilizations, where people had a desire to create entities that possessed god-like intelligence and abilities. \n",
    "\n",
    "- Humans have always been fascinated with the idea of creating something that can think, reason, and perform tasks like a human being or even better. \n",
    "\n",
    "- The pursuit of **AI** is not a new phenomenon, but rather one that has been ingrained in human consciousness for a very long time.\n",
    "\n",
    "> **Geb was the Egyptian god of the earth and a mythological member of the Ennead of Heliopolis. He could also be considered a father of snakes.**\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6c702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70694b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b2a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c25f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6edea5e8",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">e. Deep Learning Timeline</h2> \n",
    "\n",
    "<br>\n",
    "<img src=\"images/timeline.jpg\">\n",
    "<br>\n",
    "\n",
    "### **First Artifical Neuron :** \n",
    "- In 1943,  McCulloch and Pitts introduced the first artificial neuron, laying the foundation for neural networks.\n",
    "\n",
    "\n",
    "### **Perceptron :** \n",
    "- In 1958, the first perceptron  as a simple algorithm was introduced by Frank Rosenblatt, an American psychologist, for supervised learning of `binary classifiers`, inspired by the functioning of the human brain(neuron).\n",
    "\n",
    "\n",
    "### **Artificial Intelligence (AI):**\n",
    "- In 1956 , The term `Artificial Intelligence (AI)` was first coined by John McCarthy at the Dartmouth Conference.\n",
    "\n",
    "\n",
    "### **ADALINE:** \n",
    "- In 1960, ADALINE (Adaptive Linear Neuron) was introduced by Bernard Widrow and Ted Hoff at Stanford University as an improvement over the perceptron algorithm for pattern recognition tasks. \n",
    "- It could handle `continuous-valued` inputs and outputs, making it more versatile than perceptron. \n",
    "- ADALINE's primary application was in noise reduction in signals.\n",
    "\n",
    "\n",
    "### **XOR Problem:**  \n",
    "- In 1969, The XOR problem was introduced by MIT researchers Minsky & Seymour Papert. \n",
    "- The problem involved a neural network trying to learn the XOR function, which is not `linearly separable`. \n",
    "- This led to the discovery of the limitations of single-layer perceptrons and the need for more complex neural networks. \n",
    "- The solution to the XOR problem played a key role in the development of `multi-layer neural networks` and the resurgence of artificial neural networks in the 1980s.\n",
    "\n",
    "\n",
    "### **Backpropagation:**\n",
    "- In 1974, Backpropagation was first introduced by Paul Werbos in 1974. It was developed to overcome the limitations of single-layer neural networks in solving complex problems by enabling multi-layer networks to learn and adjust their weights through gradient descent. \n",
    "- Backpropagation allowed for the training of deep neural networks. It made it possible to solve complex problems such as image recognition, speech recognition, and natural language processing. \n",
    "- In 1986, the development of the backpropagation algorithm was re-introduced by Rumelhart, Hinton, and Williams, leading to a resurgence of interest in neural networks.\n",
    "\n",
    "\n",
    "### **Boltzmann Machine:** \n",
    "- In 1985, Boltzmann Machine was introducted by Geoffrey Hinton and Terry. It's a stochastic neural network that uses an energy-based model. \n",
    "- It allows for the learning and optimization of complex relationships between inputs and outputs in a distributed manner. \n",
    "- It was developed to address the limitations of traditional neural networks in capturing complex patterns and relationships in data. It has been used in various applications such as image recognition, speech recognition, and natural language processing.\n",
    "\n",
    "\n",
    "### **RNNs:** \n",
    "- In 1986, RNNs were developed to address the limitations of traditional feedforward neural networks in processing sequential data, such as speech and language, by allowing for the use of feedback loops and memory of previous inputs.\n",
    "\n",
    "\n",
    "### **CNNs:** \n",
    "- In the early 1990s, CNNs or Convolutional Neural Networks were first introduced by Yann LeCun, Yoshua Bengio, and Geoffrey Hinton . \n",
    "- The development of CNNs was motivated by the need for improved image recognition systems, as traditional neural networks were not well-suited for processing visual data. \n",
    "\n",
    "\n",
    "### **LeNet:** \n",
    "- In 1998, the `LeNet neural network` was introduced by Yann LeCun, Leon Bottou. The purpose of the network was to improve the accuracy of `handwritten digit recognition` in the field of computer vision. \n",
    "- It was specifically designed to handle **2D** inputs such as images and was one of the first successful implementations of CNNs. The LeNet formed the foundation of many modern CNN architectures used in computer vision tasks.\n",
    "\n",
    "\n",
    "### **Bidirectional Recurrent Neural Network (BRNN):** \n",
    "- In 1997, BRNN was first introduced by Mike and Kuldip K. Paliwal. The BRNN combines the capabilities of both forward and backward RNNs to improve the accuracy of sequence prediction tasks. \n",
    "- It was developed to overcome the limitations of traditional RNNs in handling long-term dependencies and to capture the contextual information in a sequence more effectively. \n",
    "- The BRNN has been used in various applications such as speech recognition, natural language processing, and image captioning.\n",
    "\n",
    "\n",
    "### **Long Short-Term Memory (LSTM):** \n",
    "- In 1997, LSTM was first introduced by Sepp Hochreiter. It was developed to overcome the `vanishing gradient` problem that occurs in traditional recurrent neural networks (RNNs) and to allow for the training of deep RNNs.\n",
    "- LSTM uses memory cells and gates to selectively remember or forget information, making it effective in modeling sequential data with long-term dependencies, such as natural language processing, speech recognition, and handwriting recognition.\n",
    "\n",
    "\n",
    "\n",
    "### **Deep Neural Network:** \n",
    "- In 2006, Geoff Hinton introduced the concept of deep learning and deep neural networks, the idea behind deep neural networks is to stack multiple layers of neurons to form a hierarchical representation of input data, allowing for the learning of increasingly complex and abstract features. \n",
    "- The main motivation behind deep neural networks is to improve the performance of machine learning models on complex tasks such as image recognition, speech recognition, and natural language processing.\n",
    "\n",
    "\n",
    "\n",
    "### **AlexNet:** \n",
    "- In 2012,  AlexNet, a deep convolutional neural network developed by Alex Krizhevsky, won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), demonstrating the power of deep learning for computer vision tasks.\n",
    "\n",
    "\n",
    "### **GoogleNet :** \n",
    "- In 2014,  Google developed a deep neural network, called a `GoogleNet`, also known as `Inception V1` that was able to recognize images of cats without being explicitly programmed to do so, further demonstrating the power of deep learning for unsupervised learning tasks.\n",
    "\n",
    "\n",
    "### **AlphaGo :** \n",
    "- In 2015,  AlphaGo is an AI program developed by DeepMind, a subsidiary of Google, that was designed to play the board game Go. \n",
    "- It became the first computer program to defeat a human professional Go player, `Lee Sedol`, in a five-game match. \n",
    "- The success of AlphaGo marked a significant milestone in the development of artificial intelligence and highlighted the potential for machine learning algorithms to tackle complex problems in new ways.\n",
    "\n",
    "\n",
    "### **Generative Adversarial Networks (GANs):** \n",
    "- In 2014, GANs were introduced by Ian Goodfellow and his colleagues. GANs were developed as a solution to the problem of unsupervised learning, where data is unlabelled and difficult to use for training machine learning models. \n",
    "- GANs use a generative model and a discriminative model in a game-like setting to learn the underlying distribution of data and generate new data samples that are similar to the original data. \n",
    "- The primary goal of GANs is to create more realistic synthetic data that can be used for various applications, such as image generation and data augmentation.\n",
    "\n",
    "\n",
    "### **GPT (Generative Pre-trained Transformer):** \n",
    "- GPT was introduced by OpenAI in June 2018. The goal was to develop a language model that could perform a wide range of natural language processing tasks with state-of-the-art performance. \n",
    "- The GPT architecture is based on the transformer model and is pre-trained on large amounts of text data to learn the patterns and relationships between words and phrases in the language. \n",
    "- The introduction of GPT has had significant implications for various applications, including chatbots, language translation, and text generation.\n",
    "\n",
    "\n",
    "### **GPT-3 (Generative Pre-trained Transformer 3):** \n",
    "- GPT-3 (Generative Pre-trained Transformer 3) was introduced by OpenAI in 2020. \n",
    "- It was designed as a state-of-the-art language processing AI model with an unprecedented number of parameters (175 billion), allowing it to generate human-like text and perform a wide range of natural language processing tasks with high accuracy. \n",
    "- The main goal of GPT-3 was to push the limits of what AI models can achieve in the field of language processing and to explore potential applications in various industries such as education, healthcare, and customer service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db4671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71843f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61610fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914db29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702309a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d88ddf2",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">f. Applications of Deep Learning</h2> \n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='images/object1.gif' align=right height=200px width=200px>\n",
    "<img src='images/object2.gif' align=right height=200px width=200px>\n",
    "\n",
    "### Image and object recognition: \n",
    "- Deep learning is widely used for image and object recognition in various applications such as security, healthcare, autonomous vehicles, and more.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src='images/object3.gif' align=right height=200px width=200px>\n",
    "<img src='images/object4.gif' align=right height=200px width=200px>\n",
    "\n",
    "### Natural language processing (NLP)\n",
    "\n",
    "- Deep learning is used in natural language processing (NLP) applications such as machine translation, sentiment analysis, chatbots, and more.\n",
    "\n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "    \n",
    "<img src='images/object5.gif' align=right height=200px width=200px>\n",
    "<img src='images/object6.gif' align=right height=200px width=200px>\n",
    "    \n",
    "### Speech Recognition Systems\n",
    "- Deep learning is used in speech recognition systems to accurately transcribe spoken words into text.\n",
    "\n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src='images/object7.gif' align=right height=200px width=200px>\n",
    "<img src='images/object8.gif' align=right height=200px width=200px>\n",
    "\n",
    "### Recommendation Systems\n",
    "- Deep learning algorithms are used in recommendation systems, such as those used by Amazon and Netflix, to suggest products or movies to customers.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src='images/object9.gif' align=right height=200px width=200px>\n",
    "<img src='images/object10.gif' align=right height=200px width=200px>\n",
    "\n",
    "### Fraud Detection Systems\n",
    "- Deep learning algorithms are used in fraud detection systems to identify fraudulent activities in banking and financial transactions.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src='images/object11.jpg' align=right height=200px width=200px>\n",
    "<img src='images/object12.gif' align=right height=200px width=200px>\n",
    "\n",
    "### HealthCare\n",
    "- Deep learning is used in medical applications such as disease diagnosis, drug discovery, and medical image analysis.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src='images/self.jpg' align=right height=200px width=200px>\n",
    "\n",
    "### Autonomous vehicles\n",
    "- Deep learning is used in autonomous vehicles for object detection, pedestrian detection, and scene recognition.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src='images/robotics.jpg' align=right height=200px width=200px>\n",
    "\n",
    "### Robotics\n",
    "- Deep learning algorithms are used in robotics for object recognition, navigation, and control.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src='images/AI.gif' align=right height=200px width=200px>\n",
    "\n",
    "### Gaming\n",
    "- Deep learning is used in gaming applications for non-player character (NPC) behavior and strategy.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src='images/music.jpg' align=right height=200px width=200px>\n",
    "\n",
    "### Music generation\n",
    "- Deep learning is used in music generation to create new and original music.\n",
    "\n",
    "\n",
    "\n",
    "### Cybersecurity\n",
    "- Deep learning algorithms are used in cybersecurity for intrusion detection and network security.\n",
    "\n",
    "### Advertising\n",
    "- Deep learning is used in advertising applications for personalized targeting and ad placement.\n",
    "\n",
    "### Agriculture\n",
    "- Deep learning is used in agriculture for crop management and yield prediction.\n",
    "\n",
    "### Energy management\n",
    "- Deep learning algorithms are used in energy management for predicting energy consumption and optimizing energy usage.\n",
    "\n",
    "### Sports\n",
    "- Deep learning is used in sports for player tracking, analysis, and prediction of game outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acdc71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b78a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160949a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02c2e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b8074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b34e659",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">h. Challenges in Deep Learning</h2> \n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong> Deep learning is not just a tool, it's a mindset. It requires a deep understanding of mathematics, statistics, and computer science, as well as a willingness to constantly learn and adapt. (Yann LeCun, AI researcher and professor.)</strong></div></p>\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "<img src=\"images/meme.jpeg\" height=300px width=400px align=right>\n",
    "\n",
    "- **Data Availability and Quality:** Deep learning needs a lot of good quality data to work properly. Getting enough data can be expensive and time-consuming.\n",
    "\n",
    "\n",
    "\n",
    "- **Computational Resources:** Deep learning is very computationally intensive and needs powerful computers to run well. These computers can be expensive and hard to find.\n",
    "\n",
    "\n",
    "- **Interpretability:** It's hard to understand how deep learning models make their predictions, making it difficult to trust and use them in certain fields.\n",
    "\n",
    "\n",
    "- **Overfitting and Generalization:** Deep learning models can be too specialized to the training data they were trained on, and can have trouble generalizing to new data.\n",
    "\n",
    "\n",
    "- **Algorithmic Complexity:** Deep learning models can be very complicated and hard to design and optimize.\n",
    "\n",
    "\n",
    "- **Hardware Limitations:** Access to powerful hardware like GPUs can be limited, which can slow down the development of new models.\n",
    "\n",
    "\n",
    "- **Security and Privacy:** Deep  learning models can be vulnerable to attacks that can trick them into making mistakes, and using sensitive data in deep learning applications can raise privacy concerns.\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48411108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815d4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5b88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7a928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd3ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d7d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dc2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a53b878",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">i. Deep Learning FrameWorks</h2> \n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong>Deep learning frameworks are essential tools for building, training, and deploying deep learning models at scale. They provide a high-level API that abstracts away the low-level details, allowing developers to focus on the task at hand. (Yann LeCun, AI researcher and professor)</strong></div></p>\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"images/framework.png\" height=500px width=500px align=right>\n",
    "\n",
    "\n",
    "- **TensorFlow:** Developed by Google, TensorFlow is one of the most popular deep learning frameworks. It supports both high-level APIs for building models quickly and low-level APIs for maximum flexibility.\n",
    "\n",
    "\n",
    "- **PyTorch:** Developed by Facebook, PyTorch is known for its easy-to-use API and dynamic computational graph, which allows for efficient experimentation and debugging.\n",
    "\n",
    "\n",
    "- **Keras:** Keras is a high-level API for building deep learning models that can run on top of TensorFlow, Theano, or CNTK. It is designed to be user-friendly and easy to learn.\n",
    "\n",
    "\n",
    "- **Caffe:** Caffe (Convolutional Architecture for Fast Feature Embedding) is a deep learning framework designed for efficient processing of image and video data. It is known for its speed and scalability.\n",
    "\n",
    "\n",
    "- **MXNet:** Developed by Amazon, MXNet is a flexible and efficient deep learning framework that supports both imperative and symbolic programming models.\n",
    "\n",
    "\n",
    "- **Microsoft Cognitive Toolkit (CNTK):** CNTK is a deep learning framework developed by Microsoft that supports both Windows and Linux. It is designed for scalable distributed training and efficient inference.\n",
    "\n",
    "\n",
    "- **Theano:** Theano is a deep learning framework that allows for efficient computation of mathematical expressions, especially in matrix algebra. It is known for its fast computation and flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f3698b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6c0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ecaf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31e9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc8ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21fa37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8375493",
   "metadata": {},
   "source": [
    "# 2. Building Blocks of a Neural Network\n",
    "\n",
    "\n",
    "\n",
    "<h2 style=\"text-align:center\">a. A Biological Neuron</h2> \n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong>A biological neuron, also known as a nerve cell, is the fundamental unit of the nervous system and plays a critical role in transmitting and processing information in the body.</strong></div></p>\n",
    "\n",
    "\n",
    "<img src=\"images/bio.png\" height=600px width=600px>\n",
    "<br>\n",
    "\n",
    "It consists of four main parts:\n",
    "\n",
    "- **Cell Body:** The central part of the neuron that contains the genetic information and metabolic machinery required to maintain the cell. It is neuron's processing unit that performs mathematical operations on the input signals.\n",
    "\n",
    "\n",
    "- **Dendrites:**  Branch-like structures that receive electrical signals from other neurons and transmit them towards the cell body. It is  neuron's input connections that receive signals from other neurons or the external environment.\n",
    "\n",
    "\n",
    "- **Axon:** A long, cable-like structure that conducts electrical impulses away from the cell body towards other neurons or muscles. It is  neuron's output connection that transmits signals to other neurons or the final output layer.\n",
    "\n",
    "\n",
    "- **Synapses:** Small gaps between neurons where neurotransmitters are released to transmit signals, allowing for communication between neurons. Synapses: The connections between neurons where the strength of the signal is adjusted during training to improve the accuracy of the neural network.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<h2 style=\"text-align:center\">Thalamocortical system visualization via DigiCortex Engine</h2> \n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong>The thalamocortical system is a complex network of connections between the thalamus (a structure in the brain that relays sensory information) and the cortex (the outer layer of the brain responsible for processing sensory and cognitive information).</strong></div></p>\n",
    "<br>\n",
    "\n",
    "<img src=\"images/one.gif\" align=right height=500px width=500px>\n",
    "<br>\n",
    "\n",
    "- The **DigiCortex Engine** is a software tool that can be used to create visualizations of the thalamocortical system, allowing researchers to better understand the complex interactions between different brain regions. The engine uses advanced computer graphics techniques to create realistic 3D models of the brain, and can simulate the behavior of neurons and synapses in real time.\n",
    "\n",
    "\n",
    "- By visualizing the thalamocortical system using the DigiCortex Engine, researchers can gain insights into how the brain processes information, how different brain regions interact with each other, and how neurological disorders may affect these interactions. This information can be used to develop new therapies and treatments for a variety of neurological and psychiatric conditions. Visualized here are `3%` of the neurons and  `0.0001%` of the synapses in the brain(16.7 Million Neurons - 2.1 Billion Synapses).\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Link: [Thalamocortical system visualization via DigiCortex Engine](https://twitter.com/lexfridman/status/1081260770464280576)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69d28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b0296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08926ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b6f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2858239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4351f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22ad16ff",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">b. Artifical Neuron</h2> \n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong> A Artificial Neuron(AN) in deep learning is a mathematical function that receives one or more inputs and produces an output. It is inspired by the biological neuron in the brain, but it is a simplified mathematical model used in artificial neural networks. It is also called Perceptron.</strong></div></p>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<img src=\"images/AN.png\" align=right width=500px height=500px>\n",
    "\n",
    "The parts of an AN and their functions are:\n",
    "\n",
    "- **Input:** The input is the information or data that is fed into the neuron. It can be one or more numerical values that represent features of the input data.\n",
    "\n",
    "\n",
    "- **Weights:** Weights are numerical values that are assigned to the inputs. They represent the strength of the connection between the input and the neuron. The weights are adjusted during the training process to improve the accuracy of the model.\n",
    "\n",
    "\n",
    "- **Bias:** The bias is a constant value added to the weighted sum of the inputs. It represents the neuron's threshold for activation.\n",
    "\n",
    "\n",
    "- **Activation function:** The activation function determines whether the neuron should fire or not based on the input and the weights. It maps the weighted sum of the inputs and the bias to an output value. Common activation functions include sigmoid, ReLU, and softmax.\n",
    "\n",
    "\n",
    "- **Output:** The output is the result of the activation function. It represents the neuron's prediction or decision based on the input data.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong>An artificial neuron takes in numerical inputs, multiplies them by learned weights, adds a bias, applies an activation function, and produces an output. The output can then be fed into other neurons to form a deep learning model.</strong></div></p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"images/neuron1.webp\" height=600px width=600px>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Mathematical Implementation\n",
    "\n",
    "Suppose we are building a model to predict whether a customer will churn (cancel their subscription) based on their purchase history. We have an artificial neuron with three inputs: \n",
    "\n",
    "- The number of purchases in the last 30 days\n",
    "- The average purchase amount\n",
    "- The customer's satisfaction score (a number between 1 and 10).\n",
    "\n",
    "Let's assume that the weights and bias for this neuron are:\n",
    "\n",
    "- **Weight1 (w1):** 0.3\n",
    "\n",
    "\n",
    "- **Weight2 (w2):** 0.5\n",
    "\n",
    "\n",
    "- **Weight3 (w3):** -0.1\n",
    "\n",
    "\n",
    "- **Bias (b):** 0.2\n",
    "\n",
    "\n",
    "The activation function is a sigmoid function:\n",
    "\n",
    "$$ \\mathbf{sigmoid(z) = \\frac{1}{ (1 + e^{(-z)})}}$$\n",
    "\n",
    "\n",
    "\n",
    "Now, suppose we have a customer with the following purchase history:\n",
    "\n",
    "- **Purchases in the last 30 days:** 6\n",
    "- **Average purchase amount:** $\\$20$\n",
    "- **Satisfaction score:** 7\n",
    "\n",
    "\n",
    "\n",
    "We can input these values into the artificial neuron, its output is:\n",
    "\n",
    "- `Weighted sum:` w1 * 6 + w2 * 20 + w3 * 7 + b = 0.3 * 6 + 0.5 * 20 - 0.1 * 7 + 0.2 = 5.5\n",
    "\n",
    "- `Output:` sigmoid(5.5) = 0.99592986228\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Result:** The output of the AN for this customer is approximately **1**, indicating a very high probability that they will not churn. This output can be used as input to other neurons in a deep neural network or as a prediction for this customer's churn probability.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66931d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad385f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df2494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd12fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85c9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83320583",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">c. A Perceptron (Single Unit Perceptron)</h2> \n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong> A perceptron is a basic computational unit of a neural network that is designed to perform binary classification of input vectors. It consists of a set of input weights, an activation function, and a threshold. The perceptron takes in input signals, applies the weights to them, sums up the weighted inputs, and then passes the result through the activation function. If the result exceeds the threshold, the perceptron outputs 1, otherwise it outputs 0.</strong></div></p>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<img src=\"images/Perceptron_1.png\" align=right width=500px height=500px>\n",
    "\n",
    "The parts of a Perceptron and their functions are:\n",
    "\n",
    "- **Input values:** These are the values that are fed into the perceptron as input.\n",
    "\n",
    "\n",
    "- **Weights:** Each input value is associated with a weight, which determines the significance of that input value in the final output.\n",
    "\n",
    "\n",
    "- **Bias:** A bias is a constant term that is added to the sum of the weighted inputs. It allows the perceptron to adjust the decision boundary.\n",
    "\n",
    "\n",
    "- **Activation function:** Usually, we use `step function` as its activation function.\n",
    "\n",
    "\n",
    "- **Threshold:** The threshold is a predefined value that is compared to the output of the activation function. If the output is greater than the threshold, the perceptron produces a positive output, otherwise it produces a negative output.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "> **Note:** It is trained using a supervised learning algorithm called the perceptron learning rule, which updates the weights based on the errors between the actual output and the desired output.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dis-Advantages of Perceptron:\n",
    "<br>\n",
    "<img src=\"images/image.png\" align=right width=450px height=450px>\n",
    "\n",
    "- **Limited to linearly separable problems:** Perceptron can only be used for classification problems that are linearly separable, meaning that a straight line can separate the data points into different classes.Perceptrons can only learn linearly separable problems such as boolean AND problem. For non-linear problems such as the boolean XOR problem, it does not work.\n",
    "\n",
    "\n",
    "- **Binary classification only:** Perceptron is only capable of binary classification, meaning that it can only classify data into two classes.\n",
    "\n",
    "\n",
    "- **Lack of hidden layers:**  Perceptron only has one layer, so it cannot capture complex patterns in the data that require multiple layers of neurons\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Mathematical Implementation\n",
    "\n",
    "Let's say we have the following inputs and weights:\n",
    "\n",
    "- `Input 1:` 2\n",
    "- `Input 2:` -3\n",
    "- `Weight 1:` 1.5\n",
    "- `Weight 2:` -2.5\n",
    "- `Bias:` 1\n",
    "\n",
    "\n",
    "We can represent this as a formula:\n",
    "\n",
    "$$\\mathbf{\\text{output = activation_function((input_1 * weight_1) + (input_2 * weight_2) + bias)}}$$\n",
    "\n",
    "\n",
    "Let's use the step function as our activation function, which returns 1 if the input is greater than or equal to 0, and 0 otherwise.\n",
    "\n",
    "Using the formula, we get:\n",
    "\n",
    "$$\\mathbf{\\text{output = step_function((2 * 1.5) + (-3 * 2.5) + 1)}}$$\n",
    "\n",
    "Simplifying, we get:\n",
    "\n",
    "$$\\mathbf{\\text{output = step_function(-4.25)}}$$\n",
    "\n",
    "> **Result:** As, -4.25 is less than 0, the step function returns 0, so the output of the perceptron in this case is 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a6e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fcd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371a6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7dafeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c0e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae904a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e333a75",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">d. Concept of Activation Functions</h2> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    " <h3><strong>Why do Neural Networks Need an Activation Function? </strong></h3>\n",
    "<br>    \n",
    "<br>    \n",
    "<strong>Introducing non-linearity: </strong> Activation functions introduce non-linearity into the output of a neuron, which allows neural networks to model more complex relationships between inputs and outputs.</div></p>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<img src=\"images/act1.jpg\" height=600px width=600px>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## 3 Types of Neural Networks Activation Functions\n",
    "\n",
    "### a. Binary Step Function \n",
    "\n",
    "<img src=\"images/act2.jpg\" height=400px width=400px align=right>\n",
    "\n",
    "- Binary step function depends on a threshold value that decides whether a neuron should be activated or not. \n",
    "\n",
    "\n",
    "- The input fed to the activation function is compared to a certain threshold; if the input is greater than it, then the neuron is activated, else it is deactivated, meaning that its output is not passed on to the next hidden layer.\n",
    "\n",
    "- Mathematically it is represented as:\n",
    "\n",
    "$$ \\mathbf{f(x) = \\begin{cases} \n",
    "        0, & x < 0 \\\\\n",
    "        1, & x \\geq 0 \n",
    "       \\end{cases}}\n",
    "$$\n",
    "\n",
    "- **Limitation**\n",
    "\t- It cannot provide multi-value outputs—for example, it cannot be used for multi-class classification problems. \n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "    \n",
    "### b. Linear Activation Function\n",
    "\n",
    "<img src=\"images/act3.jpg\" height=400px width=400px align=right>\n",
    "\n",
    "- The linear activation function, also known as `no activation` or `identity function` (multiplied x1.0), is where the activation is proportional to the input.\n",
    "\n",
    "\n",
    "- The function doesn't do anything to the weighted sum of the input, it simply spits out the value it was given.\n",
    "\n",
    "- Mathematically it is represented as:\n",
    "\n",
    "$$ \\mathbf{f(x) = x}$$\n",
    "\n",
    "- **Limitations**\n",
    "    - It’s not possible to use backpropagation as the derivative of the function is a constant and has no relation to the input x. \n",
    "    \n",
    "    - All layers of the neural network will collapse into one if a linear activation function is used. No matter the number of layers in the neural network, the last layer will still be a linear function of the first layer. So, essentially, a linear activation function turns the neural network into just one layer.\n",
    "    \n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ec24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa2ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26261409",
   "metadata": {},
   "source": [
    "\n",
    "### c. Non-Linear Activation Functions\n",
    "\n",
    "\n",
    "Non-linear activation functions solve the following limitations of linear activation functions:\n",
    "\n",
    "- They allow backpropagation because now the derivative function would be related to the input, and it’s possible to go back and understand which weights in the input neurons can provide a better prediction.\n",
    "\n",
    "\n",
    "- They allow the stacking of multiple layers of neurons as the output would now be a non-linear combination of input passed through multiple layers. Any output can be represented as a functional computation in a neural network.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<h3 style='text-align:center'>1. Sigmoid / Logistic Activation Function  </h3>\n",
    "\n",
    "<img src=\"images/act4.jpg\" height=400px width=400px align=right>\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong> This function takes any real value as input and outputs values in the range of 0 to 1. The larger the input (more positive), the closer the output value will be to 1.0, whereas the smaller the input (more negative), the closer the output will be to 0.0</strong>   \n",
    "</div></p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Mathematically it is represented as:\n",
    "\n",
    "$$ \\mathbf{sigmoid(z) = \\frac{1}{ (1 + e^{(-z)})}}$$\n",
    "\n",
    "\n",
    "- **Advantages**\n",
    "\n",
    "\t- It is commonly used for models where we have to predict the probability as an output. Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice because of its range.\n",
    "\t- The function is differentiable and provides a smooth gradient, i.e., preventing jumps in output values. This is represented by an S-shape of the sigmoid activation function. \n",
    "    \n",
    "<br>\n",
    "<img src=\"images/act5.jpg\" height=400px width=400px align=right>\n",
    "    \n",
    "<br>\n",
    "\n",
    "- **Dis-Advantages**\n",
    "\n",
    "\t- The derivative of the function is $$\\mathbf{\\text{f'(x) = sigmoid(x)*(1-sigmoid(x))}}$$. \n",
    "    \n",
    "    - The gradient values are only significant for range -3 to 3, and the graph gets much flatter in other regions.  It implies that for values greater than 3 or less than -3, the function will have very small gradients. As the gradient value approaches zero, the network ceases to learn and suffers from the Vanishing gradient problem.\n",
    "<br>\n",
    "\t- The output of the logistic function is not symmetric around zero. So the output of all the neurons will be of the same sign. This makes the training of the neural network more difficult and unstable.\n",
    "    \n",
    "    \n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07396d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1417607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a2f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1b436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6a1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4fbdca5",
   "metadata": {},
   "source": [
    "<h3 style='text-align:center'>2. Tanh Function (Hyperbolic Tangent) </h3>\n",
    "\n",
    "<img src=\"images/act6.jpg\" height=400px width=400px align=right>\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong> Tanh function is very similar to the sigmoid/logistic activation function, and even has the same S-shape with the difference in output range of -1 to 1. In Tanh, the larger the input (more positive), the closer the output value will be to 1.0, whereas the smaller the input (more negative), the closer the output will be to -1.0.</strong>   \n",
    "</div></p>\n",
    "\n",
    "\n",
    "\n",
    "- Mathematically it is represented as:\n",
    "\n",
    "$$\\mathbf{f(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}}$$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Advantages**\n",
    "\t- The output of the tanh activation function is Zero centered; hence we can easily map the output values as strongly negative, neutral, or strongly positive.\n",
    "\n",
    "\t- Usually used in hidden layers of a neural network as its values lie between -1 to; therefore, the mean for the hidden layer comes out to be 0 or very close to it. It helps in centering the data and makes learning for the next layer much easier.\n",
    "    \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **Dis-Advantages**\n",
    "\t- It also faces the problem of vanishing gradients similar to the sigmoid activation function. Plus the gradient of the tanh function is much steeper as compared to the sigmoid function.\n",
    "\n",
    "<img src=\"images/act7.jpg\" height=300px width=300px align=right>\n",
    "\n",
    "\n",
    "> **Note:**  Although both sigmoid and tanh face vanishing gradient issue, tanh is zero centered, and the gradients are not restricted to move in a certain direction. Therefore, in practice, tanh nonlinearity is always preferred to sigmoid nonlinearity.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Derivative of Tanh Activation Function**\n",
    "\n",
    "The derivative of the tanh activation function is:\n",
    "\n",
    "$$ \\mathbf{ \\frac{d}{dx} tanh(x) = 1 - tanh^2(x) }$$\n",
    "\n",
    "\n",
    "This can be also written as :\n",
    "\n",
    "$$ \\mathbf{ \\frac{d}{dx} tanh(x) = sech^2(x) }$$\n",
    "\n",
    "\n",
    "where $\\operatorname{sech}(x)$ is the hyperbolic secant function, defined as:\n",
    "\n",
    "$$ \\mathbf{ sech(x) = \\frac{1}{cosh(x)} = \\frac{2}{e^x + e^{-x}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "00cdf6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964027580075817"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementation\n",
    "\n",
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "tanh(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b4409c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of derivative of tanh function\n",
    "import math\n",
    "def tanh_derivative(x):\n",
    "    return 1 - math.tanh(x)**2\n",
    "\n",
    "\n",
    "# or \n",
    "def tanh_derivative(x):\n",
    "    sech = 1 / math.cosh(x)\n",
    "    return sech**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b3c3d156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00986603716544019"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh_derivative(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2dbbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f46bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac146f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853734d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489462df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdfe345e",
   "metadata": {},
   "source": [
    "<h3 style='text-align:center'>3. ReLU Function </h3>\n",
    "\n",
    "<img src=\"images/act8.jpg\" height=300px width=300px align=right>\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong> ReLU stands for Rectified Linear Unit. Although it gives an impression of a linear function, ReLU has a derivative function and allows for backpropagation while simultaneously making it computationally efficient. The main catch here is that the ReLU function does not activate all the neurons at the same time. The neurons will only be deactivated if the output of the linear transformation is less than 0.</strong>   \n",
    "</div></p>\n",
    "\n",
    "\n",
    "\n",
    "- Mathematically it is represented as:\n",
    "\n",
    "$$\\mathbf{f(x) = max(0,x)}$$\n",
    "\n",
    "- **Advantages**\n",
    "    - Since only   certain number of neurons are activated, the ReLU function is far more computationally efficient when compared to the sigmoid and tanh functions.\n",
    "    - ReLU accelerates the convergence of gradient descent towards the global minimum of the loss function due to its linear, non-saturating property.\n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"images/act9.jpg\" height=300px width=300px align=right>\n",
    "\n",
    "- **Dis-Advantages**\n",
    "\n",
    "\t- The `Dying Relu Problem:` The negative side of the graph makes the gradient value zero. Due to this reason, during the backpropagation process, the weights and biases for some neurons are not updated. This can create dead neurons which never get activated. \n",
    "\n",
    "\t- All the negative input values become zero immediately, which decreases the model’s ability to fit or train from the data properly. \n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "**Derivative of the ReLU Activation Function**\n",
    "\n",
    "The derivative of the ReLU activation function can be defined as follows:\n",
    "\n",
    "- If `x` is greater than or equal to 0, the derivative is 1.\n",
    "- If `x` is less than 0, the derivative is 0.\n",
    "\n",
    "In mathematical notation, we can write the derivative of Leaky ReLU as:\n",
    "\n",
    "$$ \\mathbf{f'(x) = 1, \\; if\\;  x >= 0}$$\n",
    "$$\\mathbf{f'(x) = 0, \\; if \\; x < 0}$$\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c13cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation\n",
    "\n",
    "def relu(num):\n",
    "    return max(0, num)\n",
    "inputs = np.linspace(-10,10, 1000)\n",
    "outputs = []\n",
    "for i in inputs:\n",
    "    outputs.append(relu(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bc7dd0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(inputs, outputs);\n",
    "plt.title(\"ReLu\")\n",
    "plt.xlabel(\"Inputs\")\n",
    "plt.ylabel(\"Outputs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5389d27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d69fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d63375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0680a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb71e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16ddeeb0",
   "metadata": {},
   "source": [
    "<h3 style='text-align:center'>4. Leaky ReLU Function </h3>\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong>  Leaky ReLU is an improved version of ReLU function to solve the Dying ReLU problem as it has a small positive slope in the negative area. </strong>   \n",
    "</div></p>\n",
    "\n",
    "\n",
    "<img src=\"images/act10.jpg\" height=300px width=300px align=right>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Mathematically it is represented as :\n",
    "\n",
    "$$\\mathbf{f(x) = max(0.1x, x)}$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- **Advantages**\n",
    "\n",
    "- The advantages of Leaky ReLU are same as that of ReLU, in addition to the fact that it does enable backpropagation, even for negative input values. \n",
    "\n",
    "- By making this minor modification for negative input values, the gradient of the left side of the graph comes out to be a non-zero value. Therefore, we would no longer encounter dead neurons in that region. \n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- **Dis-Advantages**\n",
    "\t- The predictions may not be consistent for negative input values. \n",
    "    - The gradient for negative values is a small value that makes the learning of model parameters time-consuming.\n",
    "    \n",
    "<img src=\"images/act11.jpg\" height=300px width=300px align=right>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "**Derivative of the Leaky ReLU Activation Function**\n",
    "\n",
    "The derivative of the Leaky ReLU activation function can be defined as follows:\n",
    "\n",
    "- If `x` is greater than or equal to 0, the derivative is 1.\n",
    "- If `x` is less than 0, the derivative is a small constant alpha.\n",
    "\n",
    "In mathematical notation, we can write the derivative of Leaky ReLU as:\n",
    "\n",
    "$$ \\mathbf{f'(x) = 1, \\; if\\;  x >= 0}$$\n",
    "$$\\mathbf{f'(x) = \\alpha, \\; if \\; x < 0}$$\n",
    "\n",
    "where alpha is a small constant, typically set to `0.01.`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "acf02b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation\n",
    "def leaky_relu(num):\n",
    "    return max(0.1*num, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f2e064c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.linspace(-10,10, 1000)\n",
    "outputs = []\n",
    "for i in inputs:\n",
    "    outputs.append(leaky_relu(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce9ed836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(inputs, outputs);\n",
    "plt.title(\"Leaky ReLu\")\n",
    "plt.xlabel(\"Inputs\")\n",
    "plt.ylabel(\"Outputs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d972317f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def leaky_relu_derivative(x, alpha=0.01):\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    else: return alpha\n",
    "leaky_relu_derivative(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700dbc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeef5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56137e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b6c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5c80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48a4f310",
   "metadata": {},
   "source": [
    "## Mathematics Recap\n",
    "- Scalar\n",
    "- Vector, 1D,2D, 3D\n",
    "- Vector Operations\n",
    "\t- Addition Operation\n",
    "    - Multiplication Operation(Element-wise & Dot Product)\n",
    "- Differential Calculus\n",
    "\t- Chain Rule\n",
    "    - Two Examples to calculate Gradient Descent of functions with valuesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1d82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed3724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9181fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20314f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b39c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef0a912d",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">e. Concept of Layers of Neural Network</h2> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    " <h3><strong> Single-layer Feedforward Neural Networks VS Multiple Hidden Layers Neural Network </strong></h3>   \n",
    "</div></p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"images/Single.png\" height=500px width=450px align=left>\n",
    "<img src=\"images/multi.jpeg\" height=500px width=400px align=right>\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "### Why Layers are used in Deep Learning?\n",
    "\n",
    "<img src=\"images/layer.webp\" height=500px width=400px>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **Feature extraction:** Each layer in a deep neural network extracts features from the input data. The initial layers capture low-level features, and the subsequent layers combine them to form higher-level features. This hierarchical feature extraction enables the network to learn complex representations of the data.\n",
    "\n",
    "- **Non-linearity:** Layers in deep learning models use non-linear activation functions that enable the network to learn complex relationships between the input and output. Non-linear activation functions like ReLU, sigmoid, and tanh introduce non-linearity into the network and enable it to approximate complex functions.\n",
    "\n",
    "- **Generalization:** Layers help in generalizing the learned features to new, unseen data. By learning features that are relevant to the task, the network can generalize better to new data and achieve better performance.\n",
    "\n",
    "- **Parameter sharing:** Layers in a neural network share parameters across different input regions. This parameter sharing reduces the number of parameters to be learned, making it easier to train deep neural networks.\n",
    "\n",
    "- **Hierarchical organization:** The use of layers in deep learning models results in a hierarchical organization of the network. This hierarchical organization enables the network to learn complex features and relationships by combining simpler features learned in earlier layers.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Single-hidden layer neural network(Multi-layer Perceptron)\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    " A single-hidden layer neural network is a type of artificial neural network architecture that consists of an input layer, a single hidden layer, and an output layer. The hidden layer sits between the input and output layers and contains one or more hidden neurons. Each neuron in the hidden layer receives input from the input layer and produces an output that is sent to the output layer. The weights and biases of the network are learned through a process called backpropagation during training.  \n",
    "</div></p>\n",
    "\n",
    "\n",
    "The layers in a single-hidden layer neural network can be defined as follows:\n",
    "\n",
    "- **Input Layer:** This layer consists of the input variables/features that are fed into the network. Each input feature is represented by a neuron in the input layer.\n",
    "\n",
    "- **Hidden Layer:** This layer contains one or more hidden neurons that perform computations on the input data. Each neuron in the hidden layer receives input from the input layer and produces an output that is sent to the output layer. The activation functions used in the hidden layer can be sigmoid, ReLU, or tanh.\n",
    "\n",
    "- **Output Layer:** This layer produces the final output of the network. The number of neurons in the output layer depends on the type of problem being solved. For example, for binary classification, there will be one output neuron that outputs a value between 0 and 1, while for multiclass classification, there will be multiple output neurons, with each neuron representing a class.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Multilayer Neural Network(Deep Neural Network)\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    " A multilayer neural network, also known as a deep neural network, is a neural network composed of more than one hidden layer. Each layer in a multilayer neural network can consist of multiple nodes, or neurons, which process information and pass it on to the next layer.\n",
    "</div></p>\n",
    "\n",
    "The layers in a multilayer neural network can be divided into three main types:\n",
    "\n",
    "- **Input layer:** The input layer receives the data to be processed by the network. Each node in the input layer represents one feature of the input data.\n",
    "\n",
    "- **Hidden layers:** The hidden layers are responsible for transforming the input data into a form that can be used to make predictions. Each node in a hidden layer receives input from the nodes in the previous layer, performs a computation, and passes the result on to the nodes in the next layer. The number of hidden layers and the number of nodes in each layer are hyperparameters that can be tuned to optimize the performance of the network.\n",
    "\n",
    "- **Output layer:** The output layer produces the final output of the network. The number of nodes in the output layer depends on the type of problem being solved. For example, in a binary classification problem, the output layer might have a single node that produces a probability of the input belonging to one of the two classes. In a multiclass classification problem, the output layer might have multiple nodes that produce probabilities of the input belonging to each class. In a regression problem, the output layer might have a single node that produces a continuous output value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f192e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92be8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff214e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d80bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae31e86c",
   "metadata": {},
   "source": [
    "# Real World Problem : Bank Transaction\n",
    "\n",
    "Let's say we want to predict the number of bank transactions a person will do in a month based on two features: - \n",
    "- The number of children they have and\n",
    "- The number of existing bank accounts they hold.\n",
    "\n",
    "\n",
    "### Simple Approach\n",
    "\n",
    "\n",
    "### Neural Network Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79811eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431fca92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8524e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b30e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033c497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6447bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a331e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023a048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3977e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef920272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625182b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91eed25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa893f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20516f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d3d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066a614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4909c76b",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">e. Implementation of Perceptron from Srcatch</h2> \n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    "Perceptron  is the most fundamental type of element in a neural network. \n",
    " \n",
    "</div></p>\n",
    "\n",
    "\n",
    "<img src=\"images/image1.png\" height=700px width=700px>\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Linearly Separable data\n",
    "\n",
    "- A **perceptron** can only solve linearly separable problems. What is a linearly separable problem ? Here are a couple of examples that show us linearly separable data. For example, two if the iris species are linearly separable by a hyperplane (in this case a single line). Similarly, an OR gate is also an example of a linearly separable dataset.\n",
    "\n",
    "<img src=\"images/image2.png\" height=700px width=700px>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ff1264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "# OR gate data\n",
    "x = np.array([[1,0],\n",
    "              [0,1],\n",
    "              [0,0],\n",
    "              [1,1]])\n",
    "y   = np.array([1,1,0,1])\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "plt.scatter(x[:,0],x[:,1],c=y)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c730a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize just 2 species (setosa, versicolor) that are linearly separable \n",
    "# using the predictors (Sepel Length, Sepal, Width)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    " \n",
    "# visualize just the first 100 rows (so that it contains only the species setosa and versicolor)\n",
    "# We are specifically not plotting the third species (virginica), because it is not linearly separable.\n",
    "plt.scatter(data[0:100,0],data[0:100,1],c=iris.target[0:100])\n",
    "plt.xlabel(\"sepal length\")\n",
    "plt.ylabel(\"sepal width\")\n",
    "plt.title(\"iris species - Setosa, Versicolor\")\n",
    "plt.savefig(\"iris.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5393c40",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "\n",
    "\n",
    "<img src=\"images/image3.png\" height=600px width=600px>\n",
    "\n",
    "\n",
    "\n",
    "What we are essentially trying to do is to find out values for weights and bias in such a way that\n",
    "\n",
    "$$ \\mathbf{activation(x_1*w_1 + x_2*w_2 + b) = output}$$\n",
    "\n",
    "The activation function in the case of perceptron is simple stepper function\n",
    "\n",
    "$$ \\mathbf{y = f(x)}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ f(x) = 1 \\; if \\; x >= 0$$\n",
    "$$ f(x) = 0 \\; if \\; x > 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9886acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Activation function - Binary step function ')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace (-5,5,100)\n",
    "y = np.zeros(len(x))\n",
    "y[x>=0] = 1\n",
    "y[x<0] = 0\n",
    " \n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Activation function - Binary step function \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd161bd6",
   "metadata": {},
   "source": [
    "### OR gate problem (or any other linearly separable problem) using a simple, single layer perceptron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fdca7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR gate data\n",
    "x = np.array([[1,0],\n",
    "              [0,1],\n",
    "              [0,0],\n",
    "              [1,1]])\n",
    "y   = np.array([1,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97537af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(row) :\n",
    "    y_hat = np.dot(x[row],w) + b\n",
    "    if y_hat > 0 :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b585eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(y_hat, row) :\n",
    "    global b,w\n",
    "    w[0]  = w[0] + alpha * (y[row] - y_hat) * x[row][0]\n",
    "    w[1]  = w[1] + alpha * (y[row] - y_hat) * x[row][1]\n",
    "    b     = b + alpha * (y[row] - y_hat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b4e0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.normal(size=2)\n",
    "b = np.random.normal()\n",
    " \n",
    "# learning rate. This is exactly the same term that we have already learnt in gradient descent.\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbad82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the predicted y_hat, for the test data set.\n",
    "def predict(x) :\n",
    "    y = []\n",
    "     \n",
    "    # the user could be sending multiple rows. compute y_hat for each of the rows in the test dataset.\n",
    "    for row in x :\n",
    "         \n",
    "        # weighted sum\n",
    "        y_pred = np.dot(row,w) + b\n",
    "         \n",
    "        # run the weighted sum throught he activation function.\n",
    "        if y_pred > 0 :\n",
    "            y_pred = 1\n",
    "        else :\n",
    "            y_pred = 0\n",
    "             \n",
    "        # append the predicted y (y_hat)to an array\n",
    "        y.append(y_pred)\n",
    "         \n",
    "    # return the predicted array of y_hat values for the corresponding test data (x)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53d2f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "for epoch in range(1000) :\n",
    "     \n",
    "    # for each row in x (cycle through the dataset)\n",
    "    for row in range(x.shape[0]) :\n",
    "         \n",
    "        # for each row in x, predict y_hat\n",
    "        y_hat = forward_prop(row)\n",
    " \n",
    "        # for each row calculate weights\n",
    "        backward_prop(y_hat,row)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cf4a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09189046 0.4951808 ] -0.07199879216526225\n"
     ]
    }
   ],
   "source": [
    "print( w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c83621b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 1]]),\n",
       " array([1, 1, 0, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53287bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df252bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95333fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02d9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d153896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab570d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d788e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039a648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99123a44",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">Iris Classification using Tensorflow</h2> \n",
    "\n",
    "\n",
    "<!-- <p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    "Perceptron  is the most fundamental type of element in a neural network. \n",
    " \n",
    "</div></p> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33001cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Tensorflow and keras library\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836e199",
   "metadata": {},
   "source": [
    "Building a neural net from scratch typically involves defining\n",
    "\n",
    "- Layers\n",
    "- Linking the layers\n",
    "- loss function\n",
    "- weight adjustments etc\n",
    "\n",
    "\n",
    "Defining these manually is very time consuming and daunting for newbies. What is needed is an abstract layer above Tensorflow, that makes building neural nets much quicker and easier.\n",
    "\n",
    "\n",
    "\n",
    "**Keras is the answer. Keras is a high level Python based API that can be used to build neural nets by leveraging Tensorflow. By the way, Tensorflow is not the only deep learning package out there. Here is a quick visual that shows us where Keras and Tensorflow stand in the hierarchy.**\n",
    "\n",
    "\n",
    "<img src=\"images/image4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f501a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    " \n",
    "# preview the iris data\n",
    "print ( iris.data[0:5,:]  ) # data\n",
    "print ( iris.target[0:5]  ) # target species\n",
    " \n",
    "# train/test split @ 20% test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data , iris.target, test_size=0.2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac96a82",
   "metadata": {},
   "source": [
    "### Step 1 – What type of neural network are we building ?\n",
    "\n",
    "**model = keras.Sequential()**\n",
    "\n",
    "- There are two types of Neural networks that can be build in Keras\n",
    "\n",
    "\t- **Sequential**\n",
    "    - **Functional**\n",
    "\n",
    "This classification is related to the structure of the Neural Network. However, most of the time we will be using Sequential model. It can solve most of the problems. In a sequential neural net, neurons are arranged in layers and in sequence . The firing and wiring happen in sequence, hence the name. \n",
    "\n",
    "\n",
    "<img src=\"images/image5.png\">\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Step 2 – How are the neurons connected ?\n",
    "\n",
    "- We are building a **Dense neural network.**\n",
    "\n",
    "```\n",
    "model.add(keras.layers.Dense(4,input_shape=(4,)))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    "A Dense neural network is one in which each neuron is connected to all other neurons in the previous and next layers. \n",
    "</div></p>\n",
    "\n",
    "<img src=\"images/image6.png\" height=700px width= 700px>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Also, with this statement, we are just building the input layer. An input layer with 4 nodes, one node for each of the inputs. Naturally, the assumption at this point would be that there would be as many nodes in the input layer as the number of inputs. So, why specify the input_shape parameter again ? In later examples we will see that the input data shape need not always match with the input nodes. We specify the input_shape parameter as a tuple. In this case the input is a 1-d vector. \n",
    "\n",
    "> **Note:** The parameter input_shape is only used when creating the first layer. The next set of steps (hidden layer and output layer) do not need this parameter.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Step 3 – Hidden Layers\n",
    "\n",
    "This is where the magic happens. Let’s try it with just one hidden layer.\n",
    "\n",
    "```\n",
    "model.add(keras.layers.Dense(8,activation=\"relu\"))\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"images/image7.png\" height=700px width= 700px>\n",
    "\n",
    "\n",
    "Irrespective of the layer (input, hidden or output), the way to add layers is using the add function. That should make things easy for us. The new parameter that we see in the hidden layer is the `activation` parameter.\n",
    "\n",
    "<img src=\"images/image8.png\" height=900px width= 900px>\n",
    "\n",
    "\n",
    "\n",
    "### Step 4 – Output Layer\n",
    "\n",
    "- After the hidden layer is added, we add the output layer. Since we are doing a multi-class classification, the preferred activation function is called as a softmax – more on this later. A softmax activation function gives out multiple probability values and the one with the highest probability is the predicted output.\n",
    "\n",
    "```\n",
    "model.add(keras.layers.Dense(3,activation=\"softmax\"))\n",
    "```\n",
    "\n",
    "<img src=\"images/image9.png\" height=900px width= 900px>\n",
    "\n",
    "\n",
    "\n",
    "### Step 5 – Compile the model\n",
    "\n",
    "- We have created the structure of the neural net – layer by layer. At each step, we have defined the number of nodes and the activation function to be used. Once we have completed it, we now have to compile the model.\n",
    "\n",
    "\n",
    "```\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "- We have just defined how the neural net should look like. With the **compile ( )** method, Keras translates the parameters you have specified into an optimized series of steps that can then be executed on the computer. Without the compile step, you cannot fit (train) the model. We will see how we can use metrics in a bit, but optimizer and loss parameters requrie quite a bit of explanation.\n",
    "\n",
    "- Typically, Machine Learning algorithm requires some kind of a loss function to be minimized. Gradient Descent is a commonly used loss function. For classification problems, a common loss function is **Cross Entropy**. Cross Entropy is also called as Log Loss. Mathematically, this is a how a cross entropy function can be defined for 2 classes.\n",
    "\n",
    "\n",
    "<img src=\"images/image10.webp\" height=900px width= 900px>\n",
    "\n",
    "\n",
    "If the model has predicted the species to be setosa with a probability of `0.2`, the loss function can be calculated as follows.\n",
    "\n",
    "\n",
    "<img src=\"images/image11.webp\" height=900px width= 900px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a00571",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([0.0001,0.001,0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99])\n",
    " \n",
    "# when y = 1, what is the loss function ?\n",
    "y = 1\n",
    "l = - (y * np.log10(p) + (1-y) * np.log10(1-p)  )\n",
    " \n",
    "# now plot it to see how the loss function decreases as the predicted value approaches the actual value (of y = 1)\n",
    " \n",
    "plt.scatter(p,l)\n",
    "plt.xlabel(\"Different predicted values when the actual value is 1\")\n",
    "plt.ylabel(\"Loss function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2b477",
   "metadata": {},
   "source": [
    "> What this plot means is that the more the predicted value deviates from the actual value, the more the loss function is. For example, when the predicted value reaches close to the actual value (of 1 in this case), the loss function gets closer and closer to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ace0c",
   "metadata": {},
   "source": [
    "### Step 6 – Fit the model with training data\n",
    "\n",
    "- This is where we train the dataset. The word `epoch` represents one complete iteration over the training dataset. With each epoc (one pass over the entire dataset) the weights are adjusted and the accuracy slowly increases. Since we have accuracy as a metric in step 5, it is shown at each of the training epoch. That way we see how the accuracy increases with each epoch.\n",
    "\n",
    "```\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "```\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Step 7 – Predict data\n",
    "\n",
    "- Once the model is trained, we can start predicting your test data. \n",
    "\n",
    "```\n",
    "model.predict(testData)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"images/image12.png\">\n",
    "\n",
    "### Step 8 – Evaluate Model\n",
    "\n",
    "Since the output is categorical data, a quick `confusion matrix` will show use how far we are from the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Step 9 – Optimize Model\n",
    "\n",
    "- There are a couple of ways to optimize for higher accuracy. One way is to increase the nodes in the hidden layer. \n",
    "\n",
    "\n",
    "    \n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">    Choosing the size and complexity of a neural network (like the numbner of nodes and the number of hidden layers) is more art than science. \n",
    "</div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation\n",
    "model = keras.Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(keras.layers.Dense(4,input_shape=(4,)))\n",
    "\n",
    "# hidden layers\n",
    "model.add(keras.layers.Dense(8,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(8,activation=\"relu\"))\n",
    "\n",
    "\n",
    "# output layer\n",
    "model.add(keras.layers.Dense(3,activation=\"softmax\"))\n",
    "\n",
    "\n",
    "# model compilation\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "    \n",
    "model.fit(X_train, y_train, epochs=100)\n",
    " \n",
    "    \n",
    "#model prediction\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0623dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc016a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "  \n",
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7368251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm , annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1da0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e50795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(4,input_shape=(4,)))\n",
    "# BEGIN change - increase the number of nodes from 8 to 20\n",
    "model.add(keras.layers.Dense(20,activation=\"relu\"))\n",
    "# END change\n",
    "model.add(keras.layers.Dense(3,activation=\"softmax\"))\n",
    " \n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "model.fit(X_train, y_train, epochs=100)\n",
    " \n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    " \n",
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(4,input_shape=(4,)))\n",
    "model.add(keras.layers.Dense(8,activation=\"relu\"))\n",
    "# BEGIN Change - add one more hidden layer\n",
    "model.add(keras.layers.Dense(8,activation=\"relu\"))\n",
    "# END Change\n",
    " \n",
    "model.add(keras.layers.Dense(3,activation=\"softmax\"))\n",
    " \n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "model.fit(X_train, y_train, epochs=100)\n",
    " \n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    " \n",
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7519d0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022f759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011a7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14cd75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49f806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2ba82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606534b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da2293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6036df6",
   "metadata": {},
   "source": [
    "# 4. Deep Learning Models & Neural Networks\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong>Deep learning models and neural networks are powerful tools that are revolutionizing many fields, from computer vision to natural language processing such as healthcare, finance, and entertainment to extract insights and make predictions from large datasets. These models are capable of learning from examples, improving their performance over time, and have shown great potential in solving complex problems.</strong></div></p>\n",
    "\n",
    "<img src=\"images/picture1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56b8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e42bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f2b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017e475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3c635e5",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">a. Deep Learning Models: Supervised Learning</h2> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    "<b>Supervised learning</b> is a type of machine learning in which an algorithm learns from labeled data to make predictions or decisions about unseen data. In deep learning, supervised learning involves using a large amount of labeled data to train a model to accurately predict a target variable based on input variables.   \n",
    "</div></p>\n",
    "\n",
    "<br>\n",
    "<img src=\"images/Supervised-learning.png\" height=500px width=400px align=left>\n",
    "<br>\n",
    "\n",
    "<img src=\"images/picture2.png\" height=500px width=500px align=right>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadbbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eecaa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd34bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e310a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa82d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3fda6f4",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"text-align:center\">b. Deep Learning Models: Un-Supervised Learning</h2> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    "In deep learning, <b>Un-Supervised learning</b> involves training a neural network on a dataset without any explicit labeling or categorization of the data. The goal is to enable the network to learn and discover underlying patterns or structure in the data without being explicitly told what to look for.</div></p>\n",
    "\n",
    "<br>\n",
    "<img src=\"images/unsupervised-learning.png\" height=500px width=400px align=left>\n",
    "<br>\n",
    "\n",
    "<img src=\"images/picture3.png\" height=500px width=500px align=right>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8688c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5cb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2926c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae28abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70faa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ecf0170",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"text-align:center\">c. Deep Learning Models: Reinforcement Learning</h2> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    "In deep learning, <b>Reinforcement learning</b> involves training an agent to learn how to interact with an environment in order to maximize a reward signal. The agent takes actions in the environment and receives feedback in the form of rewards or penalties, allowing it to learn the optimal policy for achieving its goal. </div></p>\n",
    "<br>\n",
    "<img src=\"images/Reinforcement.png\" height=600px width=600px >\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf98c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea6435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c78464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da1e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caa7b681",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"text-align:center\">d. Deep Learning Models: Hybrid/Semi-Supervised Learning</h2> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">\n",
    "In Deep Learning, <b>Hybrid/semi-supervised learning</b> combines both labeled and unlabeled data to train a deep learning model. The labeled data is used to train the model in a supervised manner, while the unlabeled data is used to assist the learning process by providing additional information to improve model performance. This approach is especially useful when obtaining large amounts of labeled data is difficult or expensive.</div></p>\n",
    "<br>\n",
    "<img src=\"images/Semi.png\" height=600px width=600px >\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43069ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea70eedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995a9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2de32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ebedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc7c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079a09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19fb179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3475d092",
   "metadata": {},
   "source": [
    "# 5. How to do Deep Learning?\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"><strong>Deep learning is a subset of machine learning that involves the use of artificial neural networks to analyze and learn from large amounts of data. The process involves feeding large amounts of data into a neural network, which is then trained to identify patterns and relationships within the data. These patterns are then used to make predictions or classify new data. The network learns by adjusting the weights of its connections between neurons, based on how well it performs on the task at hand, until it achieves the desired level of accuracy.</strong></div></p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"images/picture4.gif\" align=left height=500px width=500px>\n",
    "<img src=\"images/picture5.gif\" align=right height=500px width=450px>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc56893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421ccf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d59bb253",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">a. Deep Learning: Supervised Learning</h2> \n",
    "\n",
    "<img src=\"images/S1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e8b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb2e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0afab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3fe24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45694b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1fc94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc3248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb120f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1bd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eec9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57093a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b8425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028a3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e022bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd09c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e93eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7129ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b1ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b6dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54780d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ade04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e6866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9716ec24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f65067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dea6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03eff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ba2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293580ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fe77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e4a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e7de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc971857",
   "metadata": {},
   "source": [
    "## list of tools, techniques, and approaches in deep learning:\n",
    "\n",
    "- - Frameworks: TensorFlow, Keras, PyTorch, Caffe, Theano, MXNet\n",
    "- Neural network architectures: Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Autoencoders, Generative Adversarial Networks (GAN), Deep Belief Networks (DBN)\n",
    "- Regularization techniques: Dropout, L1 and L2 regularization, Early stopping, Batch normalization\n",
    "- Optimization techniques: Stochastic Gradient Descent (SGD), Adam, Adagrad, Adadelta, RMSprop\n",
    "- Preprocessing techniques: Data augmentation, Scaling, Normalization\n",
    "- Transfer learning: Fine-tuning pre-trained models on new tasks, feature extraction\n",
    "- Ensembling: Bagging, Boosting, Stacking\n",
    "- Hyperparameter tuning: Grid search, Random search, Bayesian optimization\n",
    "- Explainability: LIME, SHAP, Grad-CAM\n",
    "- Interpretability: Integrated Gradients, Layer-wise Relevance Propagation (LRP)\n",
    "- Reinforcement learning: Q-learning, Policy Gradient methods\n",
    "- GAN applications: Image-to-image translation, Text-to-image synthesis, Super-resolution\n",
    "- NLP techniques: Word embeddings, Attention Mechanisms, Transformers, BERT, GPT\n",
    "- Computer vision techniques: Object detection, Image segmentation, Face recognition, Pose estimation\n",
    "- Time-series analysis: LSTM, GRU, Time-series forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdbee79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6f7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "045c116c",
   "metadata": {},
   "source": [
    "## key issues in the field of deep learning:\n",
    "\n",
    "- Data quality and quantity: Deep learning models require large amounts of high-quality data to learn from. Poor quality data can lead to poor model performance and inaccurate results.\n",
    "\n",
    "- Interpretability and explainability: Deep learning models are often considered \"black boxes,\" meaning it can be difficult to understand how the model arrived at its predictions. This lack of interpretability can be a problem in applications where it is important to understand the reasoning behind a model's output.\n",
    "\n",
    "- Overfitting: Deep learning models can be prone to overfitting, where they perform well on the training data but poorly on new, unseen data. This can be addressed through techniques such as regularization and early stopping.\n",
    "\n",
    "- Computational resources: Deep learning models require significant computational resources to train and run, making them expensive and time-consuming to develop and deploy.\n",
    "\n",
    "- Bias and fairness: Deep learning models can exhibit bias and discrimination based on factors such as race, gender, and age, which can have negative impacts on marginalized groups.\n",
    "\n",
    "- Transferability: Deep learning models trained on one dataset may not generalize well to new datasets, making it difficult to apply them to new problems.\n",
    "\n",
    "- Privacy and security: Deep learning models trained on sensitive data such as medical records or financial transactions can raise concerns about privacy and security.\n",
    "\n",
    "- Adversarial attacks: Deep learning models can be vulnerable to adversarial attacks, where malicious actors introduce small changes to the input data to trick the model into producing incorrect outputs.\n",
    "\n",
    "## major challenges in the field of deep learning:\n",
    "\n",
    "- Data quality and quantity: Deep learning models require large amounts of high-quality data to learn from, which can be a challenge in many domains. Acquiring and labeling data can be expensive and time-consuming, and noisy or biased data can lead to poor model performance.\n",
    "\n",
    "- Model complexity: Deep learning models can be highly complex, with many layers and parameters, which can make them difficult to train and interpret. Choosing the right architecture and hyperparameters for a given task can be a challenging and iterative process.\n",
    "\n",
    "- Computational resources: Deep learning models require significant computational resources, including specialized hardware (such as GPUs) and large amounts of memory and storage. This can be a barrier to entry for individuals and organizations with limited resources.\n",
    "\n",
    "- Interpretability: Deep learning models can be difficult to interpret, making it challenging to understand how they arrive at their predictions. This is particularly important in domains such as healthcare and finance, where transparency and accountability are critical.\n",
    "\n",
    "- Transferability: Deep learning models can struggle to generalize to new domains or tasks, requiring significant amounts of retraining and adaptation. This can be a challenge when deploying models in real-world settings where new data or use cases may arise.\n",
    "\n",
    "- Ethical and societal implications: As with any powerful technology, deep learning has the potential to be used in ways that have ethical or societal implications. For example, biased or discriminatory models can perpetuate or exacerbate existing inequalities, while models used for surveillance or monitoring can raise privacy and civil liberties concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b94a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d105d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148345dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d9b6fe8",
   "metadata": {},
   "source": [
    "## list of tools and techniques that can be used for each phase of a deep learning project life cycle:\n",
    "\n",
    "- Problem Definition: The first step is to define the problem that you want to solve using deep learning. It involves understanding the business problem, collecting data, defining the scope, and identifying the goals.\n",
    "\n",
    "- Data Collection and Preparation: The next step is to collect data that is relevant to the problem you are trying to solve. This data may be in different formats, such as images, text, or audio. Once you have the data, you need to preprocess it to make it suitable for deep learning algorithms. This may include cleaning the data, converting it to a common format, and splitting it into training, validation, and testing sets.\n",
    "\n",
    "- Model Selection and Design: In this step, you need to select an appropriate deep learning model that can solve the problem you defined in step one. You may also need to design your own model if none of the existing models fit your problem. You need to take into consideration factors such as the size of the dataset, the complexity of the problem, and the computational resources available.\n",
    "\n",
    "- Model Training: Once you have selected the deep learning model, you need to train it using the training set. This involves feeding the model with input data and adjusting its parameters to minimize the error between the predicted and actual outputs. The training process may take several iterations, depending on the complexity of the model and the size of the dataset.\n",
    "\n",
    "- Model Evaluation: After training the model, you need to evaluate its performance using the validation set. This involves measuring metrics such as accuracy, precision, recall, and F1 score. If the model's performance is not satisfactory, you may need to revisit steps three and four.\n",
    "\n",
    "- Model Deployment: Once you are satisfied with the model's performance, you can deploy it to solve the problem in the real world. This involves integrating the model into the existing system and providing an interface for users to interact with it. You may also need to monitor the model's performance and retrain it periodically to keep it up to date.\n",
    "\n",
    "- Model Maintenance: The final step is to maintain the model by updating it with new data and retraining it periodically to improve its performance. You may also need to troubleshoot issues that arise during the model's deployment and address them promptly.\n",
    "\n",
    "\n",
    "#### Problem Definition:\n",
    "- Tools: Jupyter Notebooks, Google Colab, Anaconda\n",
    "- Techniques: Brainstorming, Research Papers, Industry Reports, Surveys\n",
    "\n",
    "#### Data Collection:\n",
    "- Tools: Web Scrapers, APIs, Data Warehouses, Open Data Sources\n",
    "- Techniques: Data Annotation, Data Cleaning, Data Pre-processing\n",
    "\n",
    "#### Data Preparation:\n",
    "- Tools: Numpy, Pandas, Matplotlib, Seaborn, Scikit-Learn\n",
    "- Techniques: Data Visualization, Exploratory Data Analysis, Feature Engineering, Data Augmentation, Data Normalization\n",
    "\n",
    "#### Model Selection:\n",
    "- Tools: Tensorflow, PyTorch, Keras, Scikit-Learn\n",
    "- Techniques: Convolutional Neural Networks, Recurrent Neural Networks, Transfer Learning, Autoencoders, Generative Adversarial Networks\n",
    "\n",
    "#### Model Training:\n",
    "- Tools: GPUs, TPUs, Cloud Computing, Distributed Computing\n",
    "- Techniques: Stochastic Gradient Descent, Batch Normalization, Dropout, Early Stopping, Hyperparameter Tuning\n",
    "\n",
    "#### Model Evaluation:\n",
    "- Tools: Scikit-Learn, Tensorboard, Keras, PyTorch\n",
    "- Techniques: Confusion Matrix, Precision, Recall, F1 Score, Receiver Operating Characteristic (ROC) Curve, Mean Squared Error (MSE)\n",
    "\n",
    "#### Model Deployment:\n",
    "- Tools: Flask, Django, AWS Lambda, AWS Sagemaker, Google Cloud Functions\n",
    "- Techniques: RESTful APIs, Docker, Kubernetes, Serverless Architecture, CI/CD Pipelines\n",
    "\n",
    "#### Model Monitoring and Maintenance:\n",
    "- Tools: Tensorboard, Prometheus, Grafana, ELK Stack, AWS CloudWatch\n",
    "- Techniques: Metrics Monitoring, Logging, Alerting, Troubleshooting, Upgrades and Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c48aa3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b5964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7ff22f2",
   "metadata": {},
   "source": [
    "## several types of deep learning:\n",
    "\n",
    "- Convolutional Neural Networks (CNNs): CNNs are commonly used for image recognition tasks. They are designed to automatically and adaptively learn spatial hierarchies of features from input data.\n",
    "\n",
    "- Recurrent Neural Networks (RNNs): RNNs are designed for sequential data, such as time series or natural language processing. They use feedback loops to enable information to persist across time steps.\n",
    "\n",
    "- Generative Adversarial Networks (GANs): GANs are used for generating new data, such as images or text. They consist of two networks, a generator and a discriminator, that are trained together to generate new data that is similar to the training data.\n",
    "\n",
    "- Autoencoders: Autoencoders are used for unsupervised learning, where the goal is to learn a representation of the input data that captures the most important features. They consist of an encoder and a decoder that are trained to reconstruct the input data.\n",
    "\n",
    "- Deep Reinforcement Learning: Deep reinforcement learning is used for decision-making tasks, where an agent learns to take actions in an environment to maximize a reward signal. It combines deep learning with reinforcement learning algorithms.\n",
    "\n",
    "- Capsule Networks: Capsule networks are a newer type of neural network that are designed to better handle hierarchical relationships between features in input data, such as object recognition in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f10ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d553c275",
   "metadata": {},
   "source": [
    "## In supervised learning, the types of deep learning include:\n",
    "\n",
    "- Convolutional Neural Networks (CNNs): CNNs are used for image and video analysis tasks such as object detection, recognition, and segmentation. They use convolutional layers to extract features from images.\n",
    "\n",
    "- Recurrent Neural Networks (RNNs): RNNs are used for sequence data such as time series, speech recognition, and natural language processing. They have the ability to remember previous inputs and use that information to make predictions.\n",
    "\n",
    "- Feedforward Neural Networks (FNNs): FNNs are the most basic type of neural network, consisting of input, hidden, and output layers. They are used for classification and regression tasks.\n",
    "\n",
    "- Deep Belief Networks (DBNs): DBNs are a type of generative model used for unsupervised learning. They consist of multiple layers of hidden units that learn to represent the data in a hierarchical manner.\n",
    "\n",
    "- Autoencoders: Autoencoders are used for unsupervised learning and dimensionality reduction. They consist of an encoder that maps input data to a lower-dimensional representation and a decoder that reconstructs the input data from the lower-dimensional representation.\n",
    "\n",
    "- Transfer Learning: Transfer learning involves using pre-trained models for new tasks. This can be done by fine-tuning the pre-trained model on a new dataset or by using the pre-trained model as a feature extractor for a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ddf40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f531465",
   "metadata": {},
   "source": [
    "## Supervised learning and unsupervised learning are two major categories of deep learning.\n",
    "\n",
    "Supervised learning involves training a model using labeled data, where the correct output is provided for each input data point. The goal of supervised learning is to learn a mapping between input and output data, such as predicting the price of a house based on its features or classifying images of handwritten digits.\n",
    "\n",
    "### Some common types of supervised deep learning include:\n",
    "\n",
    "- Feedforward Neural Networks: A neural network with one or more hidden layers that maps input to output through a series of nonlinear transformations.\n",
    "\n",
    "- Convolutional Neural Networks: A specialized type of neural network designed for image processing tasks that applies filters to input images to extract features.\n",
    "\n",
    "- Recurrent Neural Networks: A type of neural network that can process sequential data, such as text or speech, by maintaining an internal state or memory of previous inputs.\n",
    "\n",
    "On the other hand, unsupervised learning involves training a model using unlabeled data, where the input data is not labeled with the correct output. The goal of unsupervised learning is to discover patterns or structure in the data without any prior knowledge of the labels or categories.\n",
    "\n",
    "### Some common types of unsupervised deep learning include:\n",
    "\n",
    "- Autoencoders: A neural network architecture that learns to encode and decode input data, typically used for dimensionality reduction or image generation.\n",
    "\n",
    "- Clustering: A technique that groups similar data points together based on some similarity measure, such as k-means clustering.\n",
    "\n",
    "- Generative Adversarial Networks (GANs): A neural network architecture that consists of a generator and discriminator that learn to generate realistic samples of data from a given distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bd0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a762392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30cbdebd",
   "metadata": {},
   "source": [
    "## Explanation of the different types of deep learning:\n",
    "\n",
    "- Supervised Deep Learning: Supervised learning involves training a deep learning model with labeled data, where the input data is mapped to a corresponding output label. This type of deep learning is commonly used for tasks such as classification and regression. Examples of supervised learning models include convolutional neural networks (CNNs) for image classification and recurrent neural networks (RNNs) for natural language processing.\n",
    "\n",
    "- Unsupervised Deep Learning: Unsupervised learning involves training a deep learning model with unlabeled data, where the model must learn to identify patterns and structure within the data. This type of deep learning is commonly used for tasks such as clustering and dimensionality reduction. Examples of unsupervised learning models include autoencoders and generative adversarial networks (GANs).\n",
    "\n",
    "- Reinforcement Deep Learning: Reinforcement learning involves training a deep learning model to make decisions in an environment based on feedback in the form of rewards and punishments. This type of deep learning is commonly used for tasks such as game playing and robotics. Examples of reinforcement learning models include deep Q-networks (DQNs) and policy gradient methods.\n",
    "\n",
    "- Semi-supervised Deep Learning: Semi-supervised learning involves training a deep learning model with a combination of labeled and unlabeled data, where the model must learn to generalize to new, unseen data. This type of deep learning is commonly used when labeled data is limited or expensive to obtain. Examples of semi-supervised learning models include ladder networks and variational autoencoders (VAEs).\n",
    "\n",
    "- Transfer Learning Deep Learning: Transfer learning involves using a pre-trained deep learning model as a starting point for a new task, where the model is fine-tuned on a smaller dataset specific to the new task. This type of deep learning is commonly used when limited labeled data is available for the new task. Examples of transfer learning models include Inception, VGG, and ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2387d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c1e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c57fef8a",
   "metadata": {},
   "source": [
    "## Comprehensive  types of supervised deep learning\n",
    "Supervised learning is a type of deep learning where the input data is labeled with the correct output values. In supervised learning, a model is trained to learn the mapping between the input and output data. Here are some of the types of supervised deep learning:\n",
    "\n",
    "- Classification: Classification is a supervised learning task where the model is trained to predict the class label of an input data point. For example, if we have a dataset of images of animals, we can train a model to classify each image as a cat, dog, or bird.\n",
    "\n",
    "- Regression: Regression is a supervised learning task where the model is trained to predict a continuous value for an input data point. For example, if we have a dataset of housing prices, we can train a model to predict the price of a house based on its features, such as the number of bedrooms, square footage, and location.\n",
    "\n",
    "- Object Detection: Object detection is a supervised learning task where the model is trained to detect the presence and location of objects in an image. For example, if we have a dataset of images of cars on a road, we can train a model to detect the location of each car in the image.\n",
    "\n",
    "- Semantic Segmentation: Semantic segmentation is a supervised learning task where the model is trained to assign each pixel in an image to a particular class. For example, if we have a dataset of medical images, we can train a model to segment the image into different regions corresponding to different types of tissue or organs.\n",
    "\n",
    "- Sequence Modeling: Sequence modeling is a supervised learning task where the model is trained to predict the next value in a sequence based on the previous values. For example, if we have a dataset of time-series data, we can train a model to predict the next value in the sequence based on the previous values. This type of deep learning is widely used in natural language processing (NLP) for tasks such as language translation and speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45961a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f71b1320",
   "metadata": {},
   "source": [
    "## Comprehensive types of supervised deep learning:\n",
    "\n",
    "- Feedforward Neural Networks: This is the most basic form of neural network where the data flows in only one direction from input to output layer. These networks are good for classification and regression tasks.\n",
    "\n",
    "- Convolutional Neural Networks (CNNs): CNNs are specialized neural networks used for image and video recognition. They are highly effective in learning spatial hierarchies of features from images.\n",
    "\n",
    "- Recurrent Neural Networks (RNNs): RNNs are used for sequential data processing tasks such as natural language processing and speech recognition. They are capable of processing inputs of varying length and can remember previous inputs.\n",
    "\n",
    "- Long Short-Term Memory (LSTM): LSTMs are a special type of RNNs that are capable of remembering long-term dependencies. They are commonly used for speech recognition and language translation tasks.\n",
    "\n",
    "- Generative Adversarial Networks (GANs): GANs are a type of neural network used for generating new data samples. They consist of two networks – generator and discriminator – that compete with each other to generate new samples that resemble the original data.\n",
    "\n",
    "- Autoencoders: Autoencoders are used for unsupervised feature learning. They are capable of learning a compressed representation of data and can be used for tasks such as image and video compression.\n",
    "\n",
    "- Deep Belief Networks (DBNs): DBNs are multi-layer neural networks that are used for unsupervised feature learning. They are capable of learning hierarchical representations of data and can be used for tasks such as speech recognition and image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26088af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7376415b",
   "metadata": {},
   "source": [
    "## comprehensive  types of unsupervised deep learning\n",
    "Unsupervised deep learning refers to the training of neural networks on data that is not labeled or annotated. The aim is to uncover hidden structures and patterns within the data without any prior knowledge or guidance. Here are some comprehensive types of unsupervised deep learning:\n",
    "\n",
    "- Autoencoders: Autoencoders are neural networks that can learn to represent data in a compressed form, called the latent space. They are trained to reconstruct the input data from this compressed representation, and can be used for data compression, denoising, and anomaly detection.\n",
    "\n",
    "- Clustering: Clustering is a technique that groups similar data points together based on their similarity. Unsupervised deep learning can be used to cluster data points in a high-dimensional space. Deep clustering algorithms can learn more complex representations of data and can handle non-linear relationships between data points.\n",
    "\n",
    "- Generative models: Generative models are used to generate new data that is similar to the training data. Variational Autoencoders (VAE) and Generative Adversarial Networks (GANs) are examples of deep generative models. VAEs are used for image generation, while GANs are used for image and text generation.\n",
    "\n",
    "- Dimensionality Reduction: Dimensionality reduction is a technique used to reduce the number of features or variables in a dataset. Unsupervised deep learning can be used for this task by learning a lower-dimensional representation of the input data. Principal Component Analysis (PCA) and t-SNE are examples of deep dimensionality reduction techniques.\n",
    "\n",
    "- Anomaly Detection: Unsupervised deep learning can be used for anomaly detection, where the aim is to identify data points that are significantly different from the rest of the data. One-class SVM and Autoencoders are examples of deep anomaly detection techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50322f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76f27be6",
   "metadata": {},
   "source": [
    "## Types of deep learning:\n",
    "\n",
    "#### Supervised learning:\n",
    "- a. Classification\n",
    "- b. Regression\n",
    "- c. Sequence to sequence prediction\n",
    "\n",
    "#### Unsupervised learning:\n",
    "- a. Clustering\n",
    "- b. Anomaly detection\n",
    "- c. Dimensionality reduction\n",
    "- d. Generative models\n",
    "\n",
    "#### Reinforcement learning:\n",
    "- a. Q-Learning\n",
    "- b. Policy gradient methods\n",
    "- c. Actor-critic methods\n",
    "\n",
    "#### Semi-supervised learning:\n",
    "- a. Label propagation\n",
    "- b. Co-training\n",
    "- c. Generative models with labeled and unlabeled data\n",
    "\n",
    "#### Transfer learning:\n",
    "- a. Domain adaptation\n",
    "- b. Pre-trained models\n",
    "- c. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfffc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9537ea83",
   "metadata": {},
   "source": [
    "## Comprehensive list of some popular deep learning models for each type:\n",
    "\n",
    "### Types of Supervised Deep Learning Models:\n",
    "- Convolutional Neural Networks (CNN)\n",
    "- Recurrent Neural Networks (RNN)\n",
    "- Long Short-Term Memory (LSTM) Networks\n",
    "- Feedforward Neural Networks (FNN)\n",
    "- Deep Belief Networks (DBN)\n",
    "- Extreme Learning Machines (ELM)\n",
    "- Support Vector Machines (SVM)\n",
    "- Decision Trees\n",
    "- Random Forests\n",
    "- Gradient Boosting Machines (GBM)\n",
    "\n",
    "### Types of Unsupervised Deep Learning Models:\n",
    "- Autoencoders\n",
    "- Generative Adversarial Networks (GAN)\n",
    "- Boltzmann Machines\n",
    "- Restricted Boltzmann Machines (RBM)\n",
    "- Deep Boltzmann Machines (DBM)\n",
    "- Self-Organizing Maps (SOM)\n",
    "- Deep Neural Networks (DNN)\n",
    "- Variational Autoencoders (VAE)\n",
    "- Deep Convolutional Inverse Graphics Networks (DCIGN)\n",
    "- Independent Component Analysis (ICA)\n",
    "\n",
    "\n",
    "### Types of Reinforcement Deep Learning Models:\n",
    "- Q-Learning\n",
    "- Deep Q-Networks (DQN)\n",
    "- Actor-Critic Models\n",
    "- Policy Gradient Methods\n",
    "- Deep Reinforcement Learning with Double Q-Learning (DDQN)\n",
    "- Asynchronous Advantage Actor-Critic (A3C)\n",
    "- Deep Deterministic Policy Gradient (DDPG)\n",
    "- Proximal Policy Optimization (PPO)\n",
    "- Trust Region Policy Optimization (TRPO)\n",
    "- Monte Carlo Tree Search (MCTS)\n",
    "\n",
    "### Types of Semi-Supervised Deep Learning Models:\n",
    "- Self-Training\n",
    "- Co-Training\n",
    "- Tri-Training\n",
    "- Multitask Learning\n",
    "- Deep Generative Models\n",
    "- Temporal Ensembling\n",
    "- Virtual Adversarial Training\n",
    "- Consistency Regularization\n",
    "- Mean Teacher\n",
    "- Noisy Student\n",
    "\n",
    "### Types of Transfer Learning Deep Learning Models:\n",
    "\n",
    "- Pretrained Convolutional Neural Networks (CNN)\n",
    "- Fine-Tuning Pretrained CNNs\n",
    "- Multi-Task CNNs\n",
    "- Domain Adversarial Neural Networks (DANN)\n",
    "- Deep Adversarial Domain Adaptation (DADA)\n",
    "- Deep Co-Training\n",
    "- Multi-View Learning\n",
    "- Learning to Learn (L2L)\n",
    "- Deep Metric Learning\n",
    "- Unsupervised Domain Adaptation (UDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0f2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96bebe00",
   "metadata": {},
   "source": [
    "## comprehensive list of different types of deep learning algorithms for each category:\n",
    "\n",
    "## Supervised Deep Learning Algorithms:\n",
    "\n",
    "- Multilayer Perceptron (MLP)\n",
    "- Convolutional Neural Networks (CNN)\n",
    "- Recurrent Neural Networks (RNN)\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- Deep Belief Networks (DBN)\n",
    "- Extreme Learning Machines (ELM)\n",
    "- Support Vector Machines (SVM)\n",
    "- Decision Trees\n",
    "- Random Forests\n",
    "- Gradient Boosting Machines (GBM)\n",
    "- Artificial Neural Networks (ANN)\n",
    "\n",
    "### Unsupervised Deep Learning Algorithms:\n",
    "- Autoencoders\n",
    "- Restricted Boltzmann Machines (RBM)\n",
    "- Deep Boltzmann Machines (DBM)\n",
    "- Generative Adversarial Networks (GAN)\n",
    "- Deep Gaussian Mixture Models (DGMM)\n",
    "- Self-Organizing Maps (SOM)\n",
    "- Hebbian Learning Networks\n",
    "- Hopfield Networks\n",
    "- K-means Clustering\n",
    "- Hierarchical Clustering\n",
    "\n",
    "### Reinforcement Deep Learning Algorithms:\n",
    "Q-Learning\n",
    "Deep Q-Networks (DQN)\n",
    "Policy Gradients\n",
    "Actor-Critic Methods\n",
    "Deep Deterministic Policy Gradient (DDPG)\n",
    "Asynchronous Advantage Actor-Critic (A3C)\n",
    "Trust Region Policy Optimization (TRPO)\n",
    "Proximal Policy Optimization (PPO)\n",
    "\n",
    "### Semi-Supervised Deep Learning Algorithms:\n",
    "\n",
    "Semi-Supervised Variational Autoencoders\n",
    "Label Propagation\n",
    "Co-Training\n",
    "Multiview Learning\n",
    "Semi-Supervised Convolutional Neural Networks (CNN)\n",
    "Generative Adversarial Networks (GAN)\n",
    "\n",
    "### Transfer Learning Deep Learning Algorithms:\n",
    "\n",
    "Pre-trained Models (such as VGG, ResNet, Inception, etc.)\n",
    "Fine-tuning of Pre-trained Models\n",
    "One-shot Learning\n",
    "Zero-shot Learning\n",
    "Domain Adaptation\n",
    "Multi-task Learning\n",
    "Model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Techniques for Supervised Deep Learning Algorithms\n",
    "# Evaluation Techniques for Unsupervised Deep Learning Algorithms\n",
    "# Evaluation Techniques for Reinforcement Deep Learning Algorithms\n",
    "# Evaluation Techniques for Semi-Supervised Deep Learning Algorithms\n",
    "# Evaluation Techniques for Transfer Learning Deep Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54f4fb",
   "metadata": {},
   "source": [
    "## omprehensive list of evaluation techniques for different types of deep learning algorithms:\n",
    "\n",
    "### Evaluation Techniques for Supervised Deep Learning Algorithms:\n",
    "\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 Score\n",
    "Area Under the Receiver Operating Characteristic Curve (AUC-ROC)\n",
    "Confusion Matrix\n",
    "Cross-validation\n",
    "Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "### Evaluation Techniques for Unsupervised Deep Learning Algorithms:\n",
    "\n",
    "Reconstruction Error\n",
    "Clustering Accuracy\n",
    "Silhouette Coefficient\n",
    "Calinski-Harabasz Index\n",
    "Davies-Bouldin Index\n",
    "Mutual Information\n",
    "Normalized Mutual Information\n",
    "Adjusted Mutual Information\n",
    "Homogeneity, Completeness, and V-measure\n",
    "\n",
    "### Evaluation Techniques for Reinforcement Deep Learning Algorithms:\n",
    "\n",
    "Reward Function\n",
    "Policy Evaluation\n",
    "Q-Value Evaluation\n",
    "Success Rate\n",
    "Entropy\n",
    "\n",
    "### Evaluation Techniques for Semi-Supervised Deep Learning Algorithms:\n",
    "Label Propagation Accuracy\n",
    "Clustering Accuracy\n",
    "Co-Training Accuracy\n",
    "Tri-Training Accuracy\n",
    "Self-Training Accuracy\n",
    "Generative Models Accuracy\n",
    "Semi-Supervised Learning Accuracy\n",
    "\n",
    "### Evaluation Techniques for Transfer Learning Deep Learning Algorithms:\n",
    "\n",
    "Domain Adaptation Accuracy\n",
    "Fine-tuning Accuracy\n",
    "Feature Extraction Accuracy\n",
    "Cross-domain Generalization Accuracy\n",
    "Zero-shot Learning Accuracy\n",
    "One-shot Learning Accuracy\n",
    "Few-shot Learning Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f80b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82163f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7870af1",
   "metadata": {},
   "source": [
    "## comprehensive list of use cases for each type of deep learning algorithm:\n",
    "\n",
    "### Use cases of supervised deep learning algorithms:\n",
    "\n",
    "Image classification: identifying objects or features within an image, e.g., classifying a picture of a dog as a \"dog\".\n",
    "Speech recognition: converting audio signals into text, e.g., transcribing spoken words into written language.\n",
    "Sentiment analysis: determining the emotional tone of a text or speech, e.g., classifying product reviews as positive or negative.\n",
    "Fraud detection: identifying potentially fraudulent activities based on patterns in data, e.g., identifying credit card fraud.\n",
    "Predictive maintenance: predicting when maintenance is needed on machines based on sensor data, e.g., predicting when a machine will break down based on its usage patterns.\n",
    "Personalized recommendations: suggesting products or services based on a user's past behavior, e.g., recommending movies on Netflix based on a user's viewing history.\n",
    "Medical diagnosis: diagnosing diseases based on medical images or patient data, e.g., identifying cancer cells in an X-ray.\n",
    "\n",
    "### Use cases of unsupervised deep learning algorithms:\n",
    "\n",
    "Clustering: grouping similar items based on patterns in the data, e.g., grouping customers based on their purchasing behavior.\n",
    "Anomaly detection: identifying rare or unusual events based on patterns in the data, e.g., identifying fraudulent transactions in a financial dataset.\n",
    "Dimensionality reduction: reducing the number of variables in a dataset while retaining important information, e.g., compressing an image while retaining important features.\n",
    "Feature extraction: extracting important features from raw data, e.g., identifying key components of an audio signal.\n",
    "Generative models: generating new data that follows the same patterns as existing data, e.g., generating realistic images of faces or landscapes.\n",
    "\n",
    "### Use cases of reinforcement deep learning algorithms:\n",
    "\n",
    "Game AI: teaching an AI agent to play games and learn from its experiences, e.g., training an agent to play chess or Go.\n",
    "Robotics: teaching robots to perform complex tasks based on sensory inputs, e.g., navigating a maze or picking up objects.\n",
    "Autonomous vehicles: teaching vehicles to drive themselves based on sensor inputs, e.g., identifying road signs and avoiding obstacles.\n",
    "Natural language processing: teaching chatbots or virtual assistants to interact with users based on their input, e.g., responding to customer inquiries or booking reservations.\n",
    "Recommendation systems: teaching a system to suggest actions to users based on their behavior, e.g., suggesting which products to buy or movies to watch.\n",
    "\n",
    "\n",
    "### Use cases of semi-supervised deep learning algorithms:\n",
    "\n",
    "Text classification: classifying text based on a small number of labeled examples and a larger amount of unlabeled data, e.g., classifying news articles as sports or politics.\n",
    "Image segmentation: identifying objects in images based on a small number of labeled examples and a larger amount of unlabeled data, e.g., identifying different parts of a car in an image.\n",
    "Speech recognition: improving accuracy by training on a small number of labeled examples and a larger amount of unlabeled data, e.g., improving accuracy in transcribing spoken words.\n",
    "Object recognition: recognizing objects in images based on a small number of labeled examples and a larger amount of unlabeled data, e.g., identifying different types of furniture in an image.\n",
    "\n",
    "### Use cases of transfer learning deep learning algorithms:\n",
    "\n",
    "Image classification: using pre-trained models on large datasets to improve accuracy on a smaller, similar dataset, e.g., using a pre-trained model on ImageNet to classify specific objects in a different image dataset.\n",
    "Natural language processing: using pre-trained models on large language datasets to improve accuracy on a smaller, similar dataset, e.g., using a pre-trained model on a language model like GPT-2 to generate text in a specific domain or on a specific topic.\n",
    "Speech recognition: using pre-trained models on large speech datasets to improve accuracy on a smaller, similar dataset, e.g., using a pre-trained model on a general speech recognition task to recognize specific accents or languages.\n",
    "Medical diagnosis: using pre-trained models on large medical image datasets to improve accuracy on a smaller, similar dataset, e.g., using a pre-trained model on mammogram images to detect breast cancer in a specific population.\n",
    "Recommendation systems: using pre-trained models on large recommendation datasets to improve accuracy on a smaller, similar dataset, e.g., using a pre-trained model on movie ratings to recommend products to a specific group of users.\n",
    "Anomaly detection: using pre-trained models on large datasets to detect anomalies in a smaller, similar dataset, e.g., using a pre-trained model on normal behavior of a system to detect anomalies or outliers in its behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c88f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e550668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcad71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d820e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9bb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eff9faf",
   "metadata": {},
   "source": [
    "## Building Blocks of a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544fdce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c304180",
   "metadata": {},
   "source": [
    "### The linear algebra of dense layers\n",
    "There are two ways to define a dense layer in tensorflow. The first involves the use of low-level, linear algebraic operations. The second makes use of high-level keras operations.\n",
    "\n",
    "<img src=\"images/network.png\" height=400px width=400px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bias1\n",
    "bias1 = Variable(1.0)\n",
    "\n",
    "# Initialize weights1 as 3x2 variable of ones\n",
    "weights1 = Variable(ones((3, 2)))\n",
    "\n",
    "# Perform matrix multiplication of borrower_features and weights1\n",
    "product1 = matmul(borrower_features, weights1)\n",
    "\n",
    "# Apply sigmoid activation function to product1 + bias1\n",
    "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
    "\n",
    "# Print shape of dense1\n",
    "print(\"\\n dense1's output shape: {}\".format(dense1.shape))\n",
    "\n",
    "\n",
    "\n",
    "# From previous step\n",
    "bias1 = Variable(1.0)\n",
    "weights1 = Variable(ones((3, 2)))\n",
    "product1 = matmul(borrower_features, weights1)\n",
    "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
    "\n",
    "# Initialize bias2 and weights2\n",
    "bias2 = Variable(1.0)\n",
    "weights2 = Variable(ones((2, 1)))\n",
    "\n",
    "# Perform matrix multiplication of dense1 and weights2\n",
    "product2 = matmul(dense1,weights2)\n",
    "\n",
    "# Apply activation to product2 + bias2 and print the prediction\n",
    "prediction = keras.activations.sigmoid(product2 + bias2)\n",
    "print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n",
    "print('\\n actual: 1')\n",
    "\n",
    "\n",
    "# Compute the product of borrower_features and weights1\n",
    "products1 = matmul(borrower_features, weights1)\n",
    "\n",
    "# Apply a sigmoid activation function to products1 + bias1\n",
    "dense1 = keras.activations.sigmoid(products1+bias1)\n",
    "\n",
    "# Print the shapes of borrower_features, weights1, bias1, and dense1\n",
    "print('\\n shape of borrower_features: ', borrower_features.shape)\n",
    "print('\\n shape of weights1: ', weights1.shape)\n",
    "print('\\n shape of bias1: ', bias1.shape)\n",
    "print('\\n shape of dense1: ', dense1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7f35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72423435",
   "metadata": {},
   "source": [
    "### Using the dense layer operation\n",
    "We've now seen how to define dense layers in tensorflow using linear algebra. In this exercise, we'll skip the linear algebra and let keras work out the details. This will allow us to construct the network below, which has 2 hidden layers and 10 features, using less code than we needed for the network with 1 hidden layer and 3 features.\n",
    "\n",
    "<img src=\"images/network1.png\">\n",
    "\n",
    "To construct this network, we'll need to define three dense layers, each of which takes the previous layer as an input, multiplies it by weights, and applies an activation function. Note that input data has been defined and is available as a 100x10 tensor: `borrower_features`. Additionally, the `keras.layers` module is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first dense layer\n",
    "dense1 = keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
    "\n",
    "# Define a dense layer with 3 output nodes\n",
    "dense2 = keras.layers.Dense(3, activation='sigmoid')(dense1)\n",
    "\n",
    "# Define a dense layer with 1 output node\n",
    "predictions = keras.layers.Dense(1,activation='sigmoid')(dense2)\n",
    "\n",
    "# Print the shapes of dense1, dense2, and predictions\n",
    "print(\"\\n shape of input features: \", borrower_features.shape)\n",
    "print('\\n shape of dense1: ', dense1.shape)\n",
    "print('\\n shape of dense2: ', dense2.shape)\n",
    "print('\\n shape of predictions: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c95712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2016de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20486d39",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "- Sigmoid(2-classes)\n",
    "- Relu(in hidden layers)\n",
    "- softmax(for >2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification problem\n",
    "\n",
    "# Construct input layer from features\n",
    "inputs = constant(bill_amounts, float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = keras.layers.Dense(3, activation='relu')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = keras.layers.Dense(2, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print error for first five examples\n",
    "error = default[:5] - outputs.numpy()[:5]\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-classification problems\n",
    "\n",
    "# Construct input layer from borrower features\n",
    "inputs = constant(borrower_features, float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = keras.layers.Dense(8, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = keras.layers.Dense(6, activation='softmax')(dense2)\n",
    "\n",
    "# Print first five predictions\n",
    "print(outputs.numpy()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864bfdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9bfce30",
   "metadata": {},
   "source": [
    "### The Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1410678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The local minima\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Initialize x_1 and x_2\n",
    "x_1 = Variable(6.0,tf.float32)\n",
    "x_2 = Variable(0.3,tf.float32)\n",
    "\n",
    "# Define the optimization operation\n",
    "opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "for j in range(100):\n",
    "\t# Perform minimization using the loss function and x_1\n",
    "\topt.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "\t# Perform minimization using the loss function and x_2\n",
    "\topt.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# Print x_1 and x_2 as numpy arrays\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112ac19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d19b3bc2",
   "metadata": {},
   "source": [
    "### Avoiding local minima\n",
    "The previous problem showed how easy it is to get stuck in local minima. We had a simple optimization problem in one variable and gradient descent still failed to deliver the global minimum when we had to travel through local minima first. One way to avoid this problem is to use momentum, which allows the optimizer to break through local minima. We will again use the loss function from the previous problem, which has been defined and is available for you as loss_function().\n",
    "\n",
    "<img src=\"images/local_minima.png\">\n",
    "\n",
    "Several optimizers in tensorflow have a momentum parameter, including SGD and RMSprop. You will make use of RMSprop in this exercise. Note that x_1 and x_2 have been initialized to the same value this time. Furthermore, keras.optimizers.RMSprop() has also been imported for you from tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb765afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb798d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize x_1 and x_2\n",
    "x_1 = Variable(0.05,float32)\n",
    "x_2 = Variable(0.05,float32)\n",
    "\n",
    "# Define the optimization operation for opt_1 and opt_2\n",
    "opt_1 = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.99)\n",
    "opt_2 = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.00)\n",
    "\n",
    "for j in range(100):\n",
    "\topt_1.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "    # Define the minimization operation for opt_2\n",
    "\topt_2.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# Print x_1 and x_2 as numpy arrays\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c303f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77c5368b",
   "metadata": {},
   "source": [
    "### Initilization in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layer 1 weights\n",
    "w1 = Variable(tf.random.normal([23,7]))\n",
    "\n",
    "# Initialize the layer 1 bias\n",
    "b1 = Variable(ones([7]))\n",
    "\n",
    "# Define the layer 2 weights\n",
    "w2 = Variable(tf.random.normal([7,1]))\n",
    "\n",
    "# Define the layer 2 bias\n",
    "b2 = Variable(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c43399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d98ff9ac",
   "metadata": {},
   "source": [
    "### Defining  model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c89a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(w1, b1, w2, b2, features = borrower_features):\n",
    "\t# Apply relu activation functions to layer 1\n",
    "\tlayer1 = keras.activations.relu(matmul(features, w1) + b1)\n",
    "    # Apply dropout rate of 0.25\n",
    "\tdropout = keras.layers.Dropout(0.25)(layer1)\n",
    "\treturn keras.activations.sigmoid(matmul(dropout, w2) + b2)\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(w1, b1, w2, b2, features = borrower_features, targets = default):\n",
    "\tpredictions = model(w1, b1, w2, b2)\n",
    "\t# Pass targets and predictions to the cross entropy loss\n",
    "\treturn keras.losses.binary_crossentropy(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for j in range(100):\n",
    "    # Complete the optimizer\n",
    "\topt.minimize(lambda: loss_function(w1, b1, w2, b2), \n",
    "                 var_list=[w1, b1, w2, b2])\n",
    "\n",
    "# Make predictions with model using test features\n",
    "model_predictions = model(w1, b1, w2, b2, test_features)\n",
    "\n",
    "# Construct the confusion matrix\n",
    "confusion_matrix(test_targets, model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45233f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e084c844",
   "metadata": {},
   "source": [
    "### The Sequential Model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2838b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Keras sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the second dense layer\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Print the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c27f82",
   "metadata": {},
   "source": [
    "### Compiling a Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "# Apply dropout to the first layer's output\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd77d1",
   "metadata": {},
   "source": [
    "### Defining a multiple input model\n",
    "In some cases, the sequential API will not be sufficiently flexible to accommodate your desired model architecture and you will need to use the functional API instead. If, for instance, you want to train two models with different architectures jointly, you will need to use the functional API to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n",
    "m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n",
    "\n",
    "# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n",
    "m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n",
    "\n",
    "# Merge model outputs and define a functional model\n",
    "merged = keras.layers.add([m1_layer2, m2_layer2])\n",
    "model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with keras\n",
    "\n",
    "# Define a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Define a hidden layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('SGD', loss='categorical_crossentropy')\n",
    "\n",
    "# Complete the fitting operation\n",
    "model.fit(sign_language_features, sign_language_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cdc58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Metrics and validation with Keras\n",
    "\n",
    "# Define sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model.add(keras.layers.Dense(32, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "# Add activation function to classifier\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Set the optimizer, loss function, and metrics\n",
    "model.compile(optimizer='RMSProp', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add the number of epochs and the validation split\n",
    "model.fit(sign_language_features, sign_language_labels, epochs=10, validation_split=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6325bf0",
   "metadata": {},
   "source": [
    "### Evaluating models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fa945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "767d2c5f",
   "metadata": {},
   "source": [
    "### Preparing to train with Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa479a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns for bedrooms and bathrooms\n",
    "bedrooms = feature_column.numeric_column(\"bedrooms\")\n",
    "bathrooms = feature_column.numeric_column(\"bathrooms\")\n",
    "\n",
    "# Define the list of feature columns\n",
    "feature_list = [bedrooms, bathrooms]\n",
    "\n",
    "def input_fn():\n",
    "\t# Define the labels\n",
    "\tlabels = np.array(housing[\"price\"])\n",
    "\t# Define the features\n",
    "\tfeatures = {'bedrooms':np.array(housing['bedrooms']), \n",
    "                'bathrooms':np.array(housing['bathrooms'])}\n",
    "\treturn features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0481126",
   "metadata": {},
   "source": [
    "### Defining the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and set the number of steps\n",
    "model = estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[2,2])\n",
    "model.train(input_fn, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f2902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6e680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2ebb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2afc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2b7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a558d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bfbc49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c895b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e187498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5722fd44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d71656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5ebe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71575d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d14f4608",
   "metadata": {},
   "source": [
    "## Types of Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a109534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6994c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f20d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829c2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "063874f1",
   "metadata": {},
   "source": [
    "## Introduction to TensorFlow and Keras Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2de761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining tensors in TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# 0D tensor\n",
    "\n",
    "d0 = tf.ones((1,))\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d93509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D tensor\n",
    "d1 = tf.ones((2,))\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ba27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D tensor\n",
    "d2 = tf.ones((2,2))\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4228f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the 2d tensor\n",
    "d2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92306cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D tensor\n",
    "d3 = tf.ones((2,2,2))\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633db50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50d992ee",
   "metadata": {},
   "source": [
    "### Defining Constants in Tensorflow\n",
    "\n",
    "A constant is a simplest category of tensor\n",
    "- Not Trainable\n",
    "- Can have any dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764af7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a 2x3 constant\n",
    "\n",
    "tf.constant(3, shape=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1639d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a 2x2 constant\n",
    "\n",
    "tf.constant([1,2,3,4], shape=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32374119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f4f8f20",
   "metadata": {},
   "source": [
    "### Defining and Initializing Variables in Tensorflow\n",
    "\n",
    "- A variable's value can be modified. This will be useful when we want to train a model by updating its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c75a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable\n",
    "\n",
    "# Here is 1D tensor of 6 elements having float16 bit type\n",
    "a0 = tf.Variable([1,2,3,4,5,6], dtype=tf.float32)\n",
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is 1D tensor of 6 elements having int6 bit type\n",
    "a0 = tf.Variable([1,2,3,4,5,6], dtype=tf.int16)\n",
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1fa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a constant\n",
    "b = tf.constant(2, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd7c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute their product\n",
    "\n",
    "c0 = tf.multiply(a0, b)\n",
    "c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac01e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = a0*b\n",
    "c1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5633a6f4",
   "metadata": {},
   "source": [
    "### Applying the Addition Operator\n",
    "\n",
    "- The `add()` operation performs `element-wise addition` with two tensors.\n",
    "- Element-wise addition requires both tensors to have the same shape:\n",
    "    - Addition of two scalars is a scalar\n",
    "    - Addition of two vectors is a vector\n",
    "    - Addition of two matrics is a matrix.\n",
    "- The `add()` is overloaded, which means that we can also perform addition using the plus symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import constant and add from tensorflow\n",
    "\n",
    "from tensorflow import constant, add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bf37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 0-dimensional tensors\n",
    "A0 = constant([1])\n",
    "B0 = constant([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0abff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 1-dimensional tensors\n",
    "A1 = constant([1,2])\n",
    "B1 = constant([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 2-dimensional tensors\n",
    "A2 = constant([[1,2],[3,4]])\n",
    "B2 = constant([[5,6],[7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22129ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform tensor addition with add\n",
    "C0 = add(A0,B0)\n",
    "C1 = add(A1,B1)\n",
    "C2 = add(A2,B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10afd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2.numpy(), B2.numpy(), C2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac66ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c34cd478",
   "metadata": {},
   "source": [
    "### Applying the Multiplication Operator\n",
    "\n",
    "- **Element-wise multiplication** performed using `multiply()` operation\n",
    "    - The tensors must have the same shape\n",
    "    - E.g. [1,2,3] and [2,3,5]\n",
    "    \n",
    "- **Matrix Multiplication** performed with `matmul()` operator\n",
    "    - The `matmul(A,B)` operation multiplies A by B\n",
    "    - Number of columns of A must equal the number of rows of B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operators from tensorflow\n",
    "\n",
    "from tensorflow import ones, matmul, multiply\n",
    "\n",
    "# Defining tensors\n",
    "\n",
    "A0 = ones((1))\n",
    "A31 = ones([3,1])\n",
    "A34 = ones([3,4])\n",
    "A43 = ones([4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type of operations are valid?\n",
    "\n",
    "multiply(A0, A0)\n",
    "multiply(A34, A34)\n",
    "multiply(A31, A31)\n",
    "multiply(A43, A43)\n",
    "\n",
    "\n",
    "matmul(A34, A43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa80330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type of operations are invalid?\n",
    "\n",
    "# matmul(A31, A34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc07322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e5f7544",
   "metadata": {},
   "source": [
    "### Summing over tensor Dimensions\n",
    "\n",
    "- The `reduce_sum()` operator sums over the dimensions of a tensor\n",
    "    - `reduce_sum(A)` sums over all dimensions of A\n",
    "    - `reduce_sum(A,i)` sums over dimension i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operations from tensorflow\n",
    "\n",
    "from tensorflow import ones, reduce_sum\n",
    "\n",
    "# Define a 2x3x4 tensor of ones\n",
    "\n",
    "A = ones([2,3,4])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d264f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum over all the dimensions\n",
    "B = reduce_sum(A)\n",
    "\n",
    "# sum over dimension 0,1,2\n",
    "\n",
    "B0 = reduce_sum(A, 0)\n",
    "B1 = reduce_sum(A, 1)\n",
    "B2 = reduce_sum(A, 2)\n",
    "\n",
    "B, B0, B1, B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a93814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2514b9d",
   "metadata": {},
   "source": [
    "### Advanced Operations\n",
    "\n",
    "- **gradient():** Compute the slope of a function at a point.\n",
    "    - Find optimum of a function(point where gradient=0)\n",
    "- **reshape():** Reshape a tensor (e.g. 10x10 to 100x1)\n",
    "- **random():** Populates tensor with entries drawn from a probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1501c41",
   "metadata": {},
   "source": [
    "#### Gradients in Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define x\n",
    "x = tf.Variable(-1.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aeae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y within instance of GradientTape\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "#     y = x**2\n",
    "    y = tf.multiply(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dffe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the gradient of y at x=-1\n",
    "g = tape.gradient(y,x)\n",
    "g.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4517e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69255196",
   "metadata": {},
   "source": [
    "#### Reshape a grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate grayscale image\n",
    "gray= tf.random.uniform([2,2], maxval=255, dtype='int32')\n",
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eef796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape grayscale image\n",
    "tf.reshape(gray, [2*2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a13ac6",
   "metadata": {},
   "source": [
    "#### Reshape a color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78602c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate color image\n",
    "color = tf.random.uniform([2, 2, 3], maxval=255, dtype='int32')\n",
    "\n",
    "# Reshape color image\n",
    "color = tf.reshape(color, [2*2, 3])\n",
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Variable\n",
    "scalar = Variable(1.0, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffceff4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "292bfad6",
   "metadata": {},
   "source": [
    "### Train a Linear Model In Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180062af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input column\n",
    "# output column\n",
    "# slope , intercept variable\n",
    "# loss_function\n",
    "# optimizer\n",
    "# Define a linear regression model\n",
    "# Define a linear regression model\n",
    "def linear_regression(intercept, slope, features = size_log):\n",
    "\treturn intercept + slope*features\n",
    "\n",
    "# Set loss_function() to take the variables as arguments\n",
    "def loss_function(intercept, slope, features = size_log, targets = price_log):\n",
    "\t# Set the predicted values\n",
    "\tpredictions = linear_regression(intercept, slope, features)\n",
    "    \n",
    "    # Return the mean squared error loss\n",
    "\treturn keras.losses.mse(targets, predictions)\n",
    "\n",
    "# Compute the loss for different slope and intercept values\n",
    "print(loss_function(0.1, 0.1).numpy())\n",
    "print(loss_function(0.1, 0.5).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63258462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an Adam optimizer with learning rate of 0.5\n",
    "opt = keras.optimizers.Adam(0.5)\n",
    "\n",
    "for j in range(100):\n",
    "\t# Apply minimize, pass the loss function, and supply the variables\n",
    "\topt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
    "\n",
    "\t# Print every 10th value of the loss\n",
    "\tif j % 10 == 0:\n",
    "\t\tprint(loss_function(intercept, slope).numpy())\n",
    "\n",
    "# Plot data and regression line\n",
    "plot_results(intercept, slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear model into batches\n",
    "# Initialize Adam optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv('kc_house_data.csv', chunksize=100):\n",
    "\tsize_batch = np.array(batch['sqft_lot'], np.float32)\n",
    "\n",
    "\t# Extract the price values for the current batch\n",
    "\tprice_batch = np.array(batch['price'], np.float32)\n",
    "\n",
    "\t# Complete the loss, fill in the variable list, and minimize\n",
    "\topt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
    "\n",
    "# Print trained parameters\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0bff1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bfe38fa",
   "metadata": {},
   "source": [
    "## Building and Training a Simple Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa23fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96121825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397947c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8009e75e",
   "metadata": {},
   "source": [
    "## Practice Building a Neural Network for a Basic Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d39586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09fd75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02220b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7ac2dc2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e879737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c92fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c5d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "334ebe84",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde86e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1442214c",
   "metadata": {},
   "source": [
    "## Interview Questions\n",
    "- What is deep learning, and how is it different from traditional machine learning?\n",
    "- What is a neural network, and how does it work?\n",
    "- What are the applications of deep learning and neural networks?\n",
    "- What are the building blocks of a neural network?\n",
    "- What are neurons, and how do they function?\n",
    "- What is an activation function, and why is it important?\n",
    "- What are the different types of layers in a neural network?\n",
    "- What is forward propagation, and how does it work?\n",
    "- What are the different types of neural networks, and when are they used?\n",
    "- What is a Convolution Neural Network, and how does it work?\n",
    "- What is a Recurrent Neural Network, and how does it work?\n",
    "- What is TensorFlow, and how is it used in deep learning?\n",
    "- What is Keras, and how is it used in deep learning?\n",
    "- What are the advantages and disadvantages of using TensorFlow and Keras?\n",
    "- How do you build and train a simple neural network using Keras?\n",
    "- How do you load and prepare data for training a neural network?\n",
    "- What is a loss function, and how is it used in training a neural network?\n",
    "- What is an optimizer, and how is it used in training a neural network?\n",
    "- How do you evaluate the performance of a trained neural network?\n",
    "- How do you build a neural network for a basic classification problem?\n",
    "- What are some common problems that can arise when training a neural network?\n",
    "- How do you analyze the performance of a trained neural network?\n",
    "- What are some future directions for deep learning and neural networks?\n",
    "- What are some additional resources for learning about deep learning and neural networks?\n",
    "- Can you explain the concept of transfer learning and how it can be applied in deep learning for NLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79306e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a44ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf77730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db01619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24ec14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a97bfa20",
   "metadata": {},
   "source": [
    "- You will build a network that takes two numbers as an input, passes them through a hidden layer of 10 neurons, and finally outputs a single non-constrained number.\n",
    "\n",
    "- Counting parameters\n",
    "\t- You've just created a neural network. But you're going to create a new one now, taking some time to think about the weights of each layer. The Keras Dense layer and the Sequential model are already loaded for you to use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e92b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560b30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdeb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c2646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
